{"title":"Dados Geográficos","markdown":{"headingText":"Dados Geográficos","containsRefs":false,"markdown":"\n::: {.callout-tip}\n## Conteúdos\n\nIntrodução à análise espacial de dados geográficos.\n\nOs formatos de dados JSON e GEOJSON.\n\nComo obter dados através de um API.\n:::\n\n## Manipulação de dados\n\nGeometria em GeoPandas\n\n+ `Geoseries` \n+ `Geometry` \n\nOperações sobre a coluna GeoMetry\n\n+ simplificar é importar\n+ facilita a visualização\n\n```{python}\nimport geopandas as gpd\nimport folium\n\n# Simplify: https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoSeries.simplify.html\n# Exemplo Importar os dados da BGRI2021 \n# Caminho para o arquivo GeoPackage\ngpk = r\"data\\geo\\BGRI2021_1106.gpkg\"\n\n# Ler os dados do GeoPackage para um GeoDataFrame\ngdf1106 = gpd.read_file(gpk)\ngdf1106_2 = gpd.read_file(gpk)\n# Simplificar a geografia para uma precisão de 5 metros\n# Experimenta - diferentes valores para ver o efeito na geometria\ngdf1106_2['geometry'] = gdf1106_2['geometry'].simplify(tolerance=10)\n\n# ------------------\n# Mostrar a localização com Folium\n# Obter Centroid\ncentroid = gdf1106.to_crs(epsg=4326).unary_union.centroid\n\n# Criar Listagem com localização de latitude  longitude\ncenter_map = [centroid.y, centroid.x]\n# Criar Mapa e mostrar\nfolium_map = folium.Map(location=center_map, zoom_start=12, tiles='OpenStreetMap')\n\n# Adicionar Geografia folium map\n# folium.GeoJson constructor\nfolium.GeoJson(gdf1106).add_to(folium_map)\n\n# Mudar a cor\nstyle_function = lambda x: {'fillColor': '#ffffff', 'color': '#000000'}\nfolium.GeoJson(gdf1106_2, style_function=style_function).add_to(folium_map)\n\n#  Widget para controloar os diferentes layers:\nfolium.LayerControl().add_to(folium_map)\n\nfolium_map\n# Visualizar o GeoDataFrame\n#gdf1106.plot(column = 'DTMNFR21',\n#              legend = False)\n```\n\n```{python}\n# explore() forma fácil de ver uma GeoDataFrame\n\n# Mostrar a geografia do GeoDataFrame\ngdf1106_2.explore(column = 'DTMNFR21',\n              legend = True,\n                  edgecolor = 'black')\n```\n\n\nUtilizar a área de cada elemento\n\n```{python}\n#print(gdf1106.info())\n\n# Codigo que mostra como calcular a população por KM2\n\n# Verificar o CRS da GDF \nprint (gdf1106.crs)\n# Area 1º registo\nprint('BGRI21:', gdf1106.iloc[10].BGRI2021, 'Area:', gdf1106.iloc[10].geometry.area)\n\n# Adicionar nova coluna \n# Caso GDF está noutra CRS será necessario uma correção: gdf1106['geometry'].to_crs(epsg=3857).area\ngdf1106['AREA_KM2'] = gdf1106['geometry'].area / 1000000\ngdf1106['INDIV_KM2'] = gdf1106['N_INDIVIDUOS'] / gdf1106['AREA_KM2']\n\n# Mostrar resultado:\nprint(gdf1106[['DTMNFR21', 'N_INDIVIDUOS','AREA_KM2', 'INDIV_KM2']].head(10))\n\n```\n\nMostrar resultado como mapa  \n```{python}\n# Import packages\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport geopandas as gpd\n\n# Definir figura:\nf, ax = plt.subplots(1, figsize=(9, 9))\n\n# Definir Legenda \nlgnd_kwds = {'loc': 'upper left', \n             'bbox_to_anchor': (1, 1.03), \n             'ncol': 3}\n\n# Generate the choropleth and store the axis\n# natural_breaks\ngdf1106.plot(column=gdf1106.INDIV_KM2, \n              scheme='quantiles', # natural_breaks, quantiles, equal_interval \n              k=9, \n              cmap='PuBu', \n              legend=True,\n              edgecolor = 'None', # sem outline\n              legend_kwds  = lgnd_kwds,\n              ax = ax)\n \n# Remover frames, ticks e tick labels do axis\nax.set_axis_off()\n\nplt.title('População por Km2')\nplt.show()\n\n```\n\nAlterar o tipo de Geometria  \n```{python}\n#print(gdf1106.info())\n\nimport geopandas as gpd\nimport folium\n\n# Criar um novo GeoDataFrame de pontos\ngdf1106_points = gdf1106.copy()\n\n# Neste momento a Geometria ainda é de Polygons:\nprint (gdf1106_points['geometry'].iloc[0].geom_type)\n```\n\nconverter para pontos  \n```{python}\n# Calcular o centróide de cada polígono\ngdf1106_points['geometry'] = gdf1106['geometry'].centroid\n\n# Calcular ponto dentro poligono\n#gdf1106_points['geometry'] = gdf1106['geometry'].representative_point()\n\nprint(\"Geometria original e nova:\",gdf1106.iloc[0]['geometry'].geom_type,gdf1106_points.iloc[0]['geometry'].geom_type)\n\n```\n\nvisualizar resultado  \n```{python}\n# Fazer Seleção dos Registos para facilitar visualização\ngdf_pnt110657 = gdf1106_points[gdf1106_points['DTMNFR21'] == '110655']\ngdf_poly110657 = gdf1106[gdf1106['DTMNFR21'] == '110655']\n\n# --------------------------------------\n# Mostrar a localização com Folium\n# São muitos dados - visualização é lento\ncentroid = gdf_pnt110657.to_crs(epsg=4326).unary_union.centroid\n\n# Criar Listagem com localização de latitude  longitude\ncenter_map = [centroid.y, centroid.x]\n# Criar Mapa e mostrar\nfolium_map = folium.Map(location=center_map, zoom_start=15, tiles='OpenStreetMap')\n\n# Adicionar Geografia folium map\n# folium.GeoJson constructor\nfolium.GeoJson(gdf_pnt110657).add_to(folium_map)\nfolium.GeoJson(gdf_poly110657).add_to(folium_map)\n\n#  Widget para controloar os diferentes layers:\nfolium.LayerControl().add_to(folium_map)\n\nfolium_map\n```\n\ncriar nova geografia a partir de um `dissolve`  \n```{python}\nimport geopandas as gpd\n\n# Codigo que mostra um dissolve das subsecções para freguesias\n# Utilizar argumento aggfunc (default = first)\n\n# Alternativa 1: DTMNFR21 passa a ser o index - sem reset_index()\n# gdf1106_freg = gdf1106.dissolve(by='DTMNFR21', aggfunc='sum')\n\n# Alternativa 2 reset_index para manter a coluna\ngdf1106_freg = gdf1106.dissolve(by='DTMNFR21', aggfunc='sum').reset_index()\n\n\n# Mostrar Resultado da nova gdf\n# print(gdf1106_freg.info())\n\n# De seguido será necessária fazer limpeza e correção das colunas\n# Apagar Colunas desnecessários\ngdf1106_freg = gdf1106_freg.drop(columns=['BGRI2021','DTMNFRSEC21','SECNUM21','SSNUM21','SECSSNUM21','SUBSECCAO','NUTS1','NUTS2','NUTS3'])\n\n# Mudar os valores das colunas nivel superior a DTMNFR21\ngdf1106_freg['DTMN21'] = '1106'\ngdf1106_freg['DT21'] = '1106'\n\ngdf1106_freg.head()\n```\n\n```{python}\n# Mostrar o resultado (a geografia do GeoDataFrame)\ngdf1106_freg.explore(column = 'DTMNFR21',\n              legend = True,\n                  edgecolor = 'black')\n```\n\n### Operações entre Datasets\n\n*Spatial join*  \n```{python}\nimport geopandas as gpd\nimport folium\n\n# Importar Paragens de autocarro\ngpk = r\"data\\geo\\GPK_CARRIS.gpkg\"\n\n# Ler os dados do GeoPackage para um GeoDataFrame\ngdfCarris = gpd.read_file(gpk,encoding='utf-8')\n\nprint(gdfCarris.head())\n# Total de 1983 registos\nprint(gdfCarris.info())\n\n\nprint('BGRI21:', gdfCarris.iloc[10].other_tags)\n\n# ------------------\n# Mostrar a localização \ngdfCarris.explore(legend = True,\n                  edgecolor = 'black',\n                  marker_type = 'marker')\n```\n\n*Spatial join* de *polygons* para *points*  \n```{python}\n# Realizar o spatial join\ngdf_join = gpd.sjoin(gdf1106_freg, gdfCarris, how=\"inner\", predicate=\"contains\")\n\n# Limitar Colunas:\n# gdf_join = gpd.sjoin(gdf1106_freg[['DTMNFR21', 'geometry']], gdfCarris, how=\"left\", predicate=\"contains\")\n\nprint (f\"Tipo de Geometria: {gdf_join['geometry'].iloc[0].geom_type}\")\nprint (f\"Nº de Registos Input: {len(gdf1106_freg)}\")\nprint (f\"Nº de Registos Output: {len(gdf_join)}\", \"\\n\")\n\n\n#gdf_join.info()\n```\n\n*Join* de *points* para *polygons*  \n\npor exemplo, obter a freguesia para cada paragem de autocarro  \n```{python}\nimport geopandas as gpd\n\n# Perform spatial join\ngdf_join = gpd.sjoin(gdfCarris, gdf1106_freg[['DTMNFR21', 'geometry']], how='left', predicate='within')\n\n# Mostrar Resultado\nprint (f\"Tipo de Geometria: {gdf_join['geometry'].iloc[0].geom_type}\")\nprint (f\"Nº de Registos Input: {len(gdfCarris)}\")\nprint (f\"Nº de Registos Output: {len(gdf_join)}\", \"\\n\")\n\ngdf_join[['osm_id','DTMNFR21']].head()\n```\n\nobter a contagem das paragens de freguesia  \n```{python}\n#gdf1106_freg.drop(columns=['n_paragens_x','n_paragens_y'], inplace=True)\n\n# Realiza o spatial join\n# '''\n# 1. Fazer sjoin: resultado um GDF com o memso numero de registos que os pontos\n# 2. Adicionar uma nova coluna n_paragens com total de registos existentes por Freguesia\n# 3. Obter Dataframe com numero de Valores unicos \n# 4. Fazer merge do novo valor obtido com Geodataframe original\n# 5. Apagar o objecto do join\n# '''\n# Realizar o spatial join\n# Resultado terá o mesmo nº de registos que gdfCarris\ngdf_join = gpd.sjoin(gdf1106_freg, gdfCarris, how=\"inner\", predicate=\"contains\")\n\nprint (f\"Nº de Registos Output Join: {len(gdf_join)}\")\n\n\n# Contar o número de pontos em cada polígono (novo atributo n_paragens)\n# Informação está duplicada para cada Freguesia\ngdf_join[\"n_paragens\"] = gdf_join.groupby(\"DTMNFR21\")[\"geometry\"].transform(\"size\")\n\n# # Selecionar o primeiro valor de 'n_paragens' dentro de cada grupo 'DTMNFR21'\nunique_values = gdf_join.groupby('DTMNFR21')['n_paragens'].first().reset_index()\n\nprint(unique_values.info())\n\n# Exibir o DataFrame resultante\n#print(unique_values.head())\n\n# Apagar coluna - caso repetir o codigo (o merge) sem recriar gdf1106\n# gdf1106_freg.drop(columns=['n_paragens','n_paragens_x','n_paragens_y'], inplace=True)\ngdf1106_freg = gdf1106_freg.merge(unique_values, on='DTMNFR21', how='left')\n\ndel gdf_join\n\n\n# Exibir a GeoDataFrame resultante com o atributo 'n_paragens' adicionado\n# print(gdf1106_freg.info())\nprint(gdf1106_freg[['DTMNFR21', 'n_paragens']].head(10))\n```\n\n\n```{python}\n# Desenhar mapa com resultado:\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\n# Definir Legenda \nlgnd_kwds = {'loc': 'upper left', \n             'bbox_to_anchor': (1, 1.03), \n             'ncol': 2}\n\n# Generate the choropleth and store the axis\n# natural_breaks\nax = gdf1106_freg.plot(column=gdf1106_freg.n_paragens, \n                      scheme='quantiles', # natural_breaks, quantiles, equal_interval \n                      k=5, \n                      cmap='YlGn', \n                      legend=True,\n                      edgecolor = 'None', \n                      legend_kwds  = lgnd_kwds)\n \n# Remover frames, ticks e tick labels do axis\nax.set_axis_off()\n\nplt.title('Nº de paragens Carris')\nplt.show()\n\n\n```\n\n\noutra possibilidade - fazer a seleção de nº de pontos para freguesia específica  \n```{python}\n# Fazer seleção de nº de pontos para freguesia especifica\nfrom geopandas.tools import sjoin\n\n# Selecionar o polígono específico da freguesia 110655 (Areeiro)\npoligono_especifico = gdf1106_freg[gdf1106_freg['DTMNFR21'] == '110655']\n\n# Fazer Join com gdfCArris para obter os pontos\njoined = sjoin(gdfCarris, poligono_especifico, how='inner', predicate='within')\n\n# Contar quantos pontos estão dentro do polígono específico\nquantidade_pontos = len(joined)\n\n# Mostrar o resultado\nprint(f\"Quantidade de paragens de autocarro dentro a freguesia 110655: {quantidade_pontos}\")\n```\n\nefectuar um *overlay*\n\nexemplo de cortar um círculo (buffer) em volta e um ponto  \n```{python}\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport contextily as ctx\nfrom shapely.geometry import Point\n\n# Criar variáveis para a figura\nf, ax = plt.subplots(1, figsize=(9, 9))\n\n# Criar um objeto Point\n# Atenção primeiro o valor x (longitude) e depois o y (latitutde) - Google Maps devolve Latitude, Longitude\nponto = Point(-9.184111016,38.768216306)\n# 38.76821630632057, -9.184111016081756\n# Cria um GeoDataFrame do ponto com CRS WGS84\ngdf_ponto = gpd.GeoDataFrame([1], geometry=[ponto], crs='EPSG:4326')\n\n# Mudar a projeção do pontos para a projeção da gdf1106:\ngdf_ponto = gdf_ponto.to_crs(gdf1106.crs)\n\nprint (f\"Tipo de Geometria: {gdf_ponto['geometry'].iloc[0].geom_type}\")\n\n# Cria um buffer de 500 metros em volta do ponto\ngdf_ponto['geometry'] = gdf_ponto.geometry.buffer(1500)\nprint (f\"Tipo de Geometria: {gdf_ponto['geometry'].iloc[0].geom_type}\")\n\n# Realiza a interseção entre o buffer e os polígonos\n# Opções: intersection’, ‘union’, ‘identity’, ‘symmetric_difference’ or ‘difference’ \nintersecao = gpd.overlay(gdf1106, gdf_ponto, how='symmetric_difference')\n\n# Visualizar o Resultado\nintersecao.plot(column = 'DTMNFR21',\n              legend = False,\n               ax = ax)\n\n# Add basemap do contextily\nctx.add_basemap(\n    ax,\n    crs=intersecao.crs,\n    source=ctx.providers.CartoDB.VoyagerNoLabels,\n)\n\n\nax.set_axis_off()\n\nplt.show()\n```\n\n\n### Exportar dados GeoDataframe\n\nprincipais formatos de output\n\n- Shapefile: Sem necessidade de especificar driver\n- GeoJSON: driver='GeoJSON'\n- GeoPackage: driver='GPKG'\n\n```{python}\ngdf1106_freg.to_file(r'data\\geo\\c2021_fr1106.gpkg', layer='FR1106', driver=\"GPKG\")\n```\n\nlistar outputs possíveis  \n```{python}\nimport fiona\nfiona.supported_drivers\n```\n\nexemplo para obter informação a partir de uma seleção dentro dum `buffer`  \n\nimportar dados  \n```{python}\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\n# Simplify: https://geopandas.org/en/stable/docs/reference/api/geopandas.GeoSeries.simplify.html\n# Exemplo Importar os dados da BGRI2021 \n# Caminho para o arquivo GeoPackage\ngpk = r'data\\geo\\BGRI2021_1106.gpkg'\n\n# Ler os dados do GeoPackage para um GeoDataFrame\ngdf1106 = gpd.read_file(gpk,encoding='utf-8')\n```\n\nmostrar mapa como follium \n```{python}\n# Function para mostrar folium\ndef mostrarFolium(gdfExtent,gdfDesenhar):\n    centroid = gdfExtent.to_crs(epsg=4326).unary_union.centroid\n\n    # Criar Listagem com localização de latitude  longitude\n    center_map = [centroid.y, centroid.x]\n    # Criar Mapa e mostrar\n    folium_map = folium.Map(location=center_map, zoom_start=15, tiles='OpenStreetMap')\n\n    # Adicionar Geografia folium map\n    # folium.GeoJson constructor\n    for lay in gdfDesenhar:\n        folium.GeoJson(lay).add_to(folium_map)\n    \n    folium_map\n```\n\nexecutar o *buffer*  \n```{python}\nfrom shapely.geometry import Point\n\n# Cria um objeto Point (podem escolher um ponto no google maps)\n# Atenção primeiro o valor x (longitude) e depois o y (latitutde)\nponto = Point(-9.137616,38.738561)\n\n# Cria um GeoDataFrame do ponto com CRS WGS84\ngdf_ponto = gpd.GeoDataFrame([1], geometry=[ponto], crs='EPSG:4326')\n\n# Manteer ponto Original\ngdf_ponto_original = gdf_ponto.copy()\n\n# Mudar a projeção:\ngdf_ponto = gdf_ponto.to_crs(gdf1106.crs)\n\n# Fazer o Buffer\ngdf_ponto['geometry'] = gdf_ponto.geometry.buffer(500)\n\n# Executar o Spatial join entre o ponto e as subsecções da BGRI2021\njoin = gpd.sjoin(gdf1106, gdf_ponto, how=\"inner\", predicate='intersects')\n\n# Somar os valores do atributo N_INDIVIDUOS\nsoma = join['N_INDIVIDUOS'].sum()\n\nprint(f\"Soma de N_INDIVIDUOS nos polígonos selecionados: {soma} em volta do ponto ({ponto.y},{ponto.x})\")\n\n\n#-----------------------------------------------------------------\n# Mostrar \nmostrarFolium(gdf_ponto,[gdf_ponto,gdf_ponto_original])\n```\n\n## Desafio\n\n- Definir um ponto, valores latitude e longitude\n- Criar um Buffer em volta desse ponto\n- Fazer o cálculo da população nas subsecções envolventes\n\nPodem fazer download de outros GPK no site do INE: https://mapas.ine.pt/download/index2021.phtml\n\n```{python}\n# Exemplo Importar os dados da BGRI2021 para o municipio de Valongo\n# Caminho para o arquivo GeoPackage\ngpk = r'data\\geo\\BGRI2021_1315.gpkg'\n\n# Ler os dados do GeoPackage para um GeoDataFrame\ngdf1315 = gpd.read_file(gpk,encoding='utf-8')\n\nfrom shapely.geometry import Point\n\n# Cria um objeto Point (podem escolher um ponto no google maps)\n# Atenção primeiro o valor x (longitude) e depois o y (latitutde)\n# ponto do google maps Sta Rita (Ermesinde)\n# 41.20722032311807, -8.541960984473912\nponto = Point(-8.541960984473912,41.20722032311807)\n\n# Cria um GeoDataFrame do ponto com CRS WGS84\ngdf_ponto = gpd.GeoDataFrame([1], geometry=[ponto], crs='EPSG:4326')\n\n# Manteer ponto Original\ngdf_ponto_original = gdf_ponto.copy()\n\n# Mudar a projeção:\ngdf_ponto = gdf_ponto.to_crs(gdf1315.crs)\n\n# Fazer o Buffer\ngdf_ponto['geometry'] = gdf_ponto.geometry.buffer(500)\n\n# Executar o Spatial join entre o ponto e as subsecções da BGRI2021\njoin = gpd.sjoin(gdf1315, gdf_ponto, how=\"inner\", predicate='intersects')\n\n# Somar os valores do atributo N_INDIVIDUOS\nsoma = join['N_INDIVIDUOS'].sum()\n\nprint(f\"Soma de N_INDIVIDUOS nos polígonos selecionados: {soma} em volta do ponto ({ponto.y},{ponto.x})\")\n\nmostrarFolium(gdf_ponto,[gdf_ponto,gdf_ponto_original])\n```\n\n## GeoEstatistica\n\n+ Análise de Padroes espaciais\n\n    - autocorrelação espacial\n    - Média do vizinho mais próximo\n\n+ Mapeamento de clusters\n\n    - Análise de clusters e outliers\n    - Análise de Hot Spots\n    - Clusterização multivariada\n    - Indices compostos\n    \n+ Modelação de relações espaciais\n\n    - Regressão linear\n    - Regressão geograficamente ponderada\n    - Regressão multiescalar geograficamente opnderada\n    - Minimos quadrados\n    - Relações locais bivariadas\n\n### Autocorrelação Espacial\n\nClacular medidas\n\n    - Moran Global\n    - Moran Local\n    - Getis and Ord's local statistics\n    \n```{python}\n#| warning: false  \nimport matplotlib.pyplot as plt  # Graphics\nfrom matplotlib import colors\nimport seaborn as sns  # Graphics\nimport geopandas as gpd # Spatial data manipulation\nimport pandas as pd  # Tabular data manipulation\n# Para Evitar Aviso Point Patterns\nfrom shapely.geometry import Point\n\n# Bibliotecas pysal\nimport pysal.lib # importação geral\nfrom pysal.explore import esda  # Exploratory Spatial analytics\nfrom pysal.lib import weights  # Spatial weights\nimport contextily  # Background tiles\n\n# Bibliotecas última parte notebook exemplo\n#import rioxarray  # Surface data manipulation\n#import xarray  # Surface data manipulation\n```\n\nimportar dados do Geopackage com variáveis do C2021 da BRGI2021  \n```{python}\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\n# Caminho para o arquivo GeoPackage\ngpk = r'data\\geo\\BGRI2021_1106.gpkg'\n\n# Ler os dados do GeoPackage para um GeoDataFrame\ngdf1106 = gpd.read_file(gpk)\n\n# Simplificar a geografia para uma precisão de 5 metros\ngdf1106['geometry'] = gdf1106['geometry'].simplify(tolerance=5)\n\n# Visualizar o GeoDataFrame\ngdf1106.plot(column = 'DTMNFR21',\n              legend = False)\n```\n\nadicionar alguns atributos que permitem fazer a análise   \n```{python}\n# Calcular Novo Atributo Racio de População 65+ anos\ngdf1106['IND65'] = gdf1106.N_INDIVIDUOS_65_OU_MAIS/gdf1106.N_INDIVIDUOS\n\n# Calcular Outros Atributos de interesse para Analisar: , N_EDIFICIOS_3_OU_MAIS_PISOS, N_INDIVIDUOS_H, N_INDIVIDUOS_M\ngdf1106['IND14'] = gdf1106.N_INDIVIDUOS_0_14/gdf1106.N_INDIVIDUOS\ngdf1106['IND_H'] = gdf1106.N_INDIVIDUOS_H/gdf1106.N_INDIVIDUOS\ngdf1106['IND_M'] = gdf1106.N_INDIVIDUOS_M/gdf1106.N_INDIVIDUOS\ngdf1106['EDIF_3PISOS'] = gdf1106.N_EDIFICIOS_3_OU_MAIS_PISOS/gdf1106.N_EDIFICIOS_CLASSICOS\n\n\n# Mostrar Dados\nprint(gdf1106[['BGRI2021', 'DTMNFR21', 'N_INDIVIDUOS_65_OU_MAIS', 'N_INDIVIDUOS', 'IND65', 'IND14', 'IND_H', 'IND_M','EDIF_3PISOS']].head(10))\n\n\n# Manter apenas as colunas de interesse: (não é necessário - simplifica o GeoDataFrame)\nmanter_colunas = ['geometry','BGRI2021', 'DTMNFR21', 'N_INDIVIDUOS_65_OU_MAIS', 'N_INDIVIDUOS', 'IND65','IND14', 'IND_H', 'IND_M','N_EDIFICIOS_CLASSICOS','EDIF_3PISOS']\ngdf1106 = gdf1106.loc[:, manter_colunas]\n\n#print(gdf1106.info())\n```\n\ntartar `NaN`  \n```{python}\n# Contar o número total de NaNs no DataFrame\ntotal_nans = gdf1106.isna().sum().sum()\nprint('Número total de registros com NaN:', total_nans)\n\n# Contar o número de NaNs em cada coluna\nnans_por_coluna = gdf1106.isna().sum()\nprint('Número de registros com NaN por coluna:\\n', nans_por_coluna)\n\n# Corrigir NaN\n# Existem 2 possibilidades\n# 1. Deixar fora\n#gdf1106 = gdf1106.dropna()\n# 2. Substituir por outros valores\ngdf1106 = gdf1106.fillna(0)\n```\n\nvisualização inicial  \n```{python}\n# Set up figure and a single axis\nf, ax = plt.subplots(1, figsize=(9, 9))\n# Build choropleth\ngdf1106.plot(\n    column=\"IND65\",\n    cmap=\"viridis\",\n    scheme=\"quantiles\",\n    k=5,\n    edgecolor=\"white\",\n    linewidth=0.0,\n    alpha=0.75,\n    legend=True,\n    legend_kwds=dict(loc=2),\n    ax=ax,\n)\n# Add basemap\ncontextily.add_basemap(\n    ax,\n    crs=gdf1106.crs,\n    source=contextily.providers.CartoDB.VoyagerNoLabels,\n)\n# Remove axes\nax.set_axis_off()\n\nplt.show()\n```\n\n### Matriz de vizinhança e Moran Global\n\n**Queen**\n\nf we wanted them to be considered as neighbours, we can switch to the more inclusive notion of Queen contiguity, which requires the pair of polygons to only share one or more vertices. We can create the neighbor relations for this same configuration as follows:\n\n**KNN**\n\nThe first type of distance based weights defines the neighbor set of a particular observation as containing its nearest \n observations, where the user specifies the value of \n. To illustrate this for the San Diego tracts, we take \n. This still leaves the issue of how to measure the distance between these polygon objects, however. To do so we develop a representative point for each of the polygons using the centroid.\n\n\n```{python}\nfrom pysal.model import spreg\n\n# Input gdf1106 (BGRI de Lisboa)\n\n# Calcular a matriz de pesos espaciais\n# Metodo Original: 0.13069266093679838 e Valor-p: 0.001\nw = pysal.lib.weights.Queen.from_dataframe(gdf1106, use_index=True)\n# Metodo knn (I de Moran: 0.11720923169446687; Valor-p: 0.001)\n#w = pysal.lib.weights.KNN.from_dataframe(gdf1106, k=5)\n\n# Lidar com ilhas\n# Normalizar a matriz de pesos\n# Row-standardization \nw.transform = \"r\"\n\n# Corrigir para ilhas\n#w.set_transform('r')\nislands = w.islands\nif islands:\n    for island in islands:\n        w.neighbors[island] = [island]\n        w.weights[island] = [1]  \n```\n\n\n```{python}\n# Selecionar a coluna com a percentagem de população superior a 65 anos\ndata = gdf1106['IND65']\n\n# Calcular a estatística de Moran\nmoran = esda.Moran(data, w)\n\n# Imprimir o valor I de Moran e o valor-p\nprint('I de Moran:', moran.I)\nprint('Valor-p:', moran.p_sim)\n\n# Plotar o gráfico de dispersão de Moran (desatividado - vai ser efetuado em tarefas na próxima seção)\n#plot_moran(moran, zstandard=True, fill=True, figsize=(10,4))\n```\n\n**Interpretação do valor Moran Global**\n\n$H_0: I = 0$ (padran aleatorio) _vs_ $H_1 \\ne 0$ (padrão espacial com clusters)\n\n\n\n### Motivating local spatial autocorrelation (Moran Plot)\n\nNesta Parte é efetuado o seguinte:  \n\n- Calcular o Spatial Lag\n- Calcular as versões centradas\n- Criar um Scatterplot\n- Visualizar a distribuição dos valores em relação ao médio e aos valores nos polígonos vizinhos\n\n**Moran Plot**\n\nThe Moran Plot is a way of visualizing a spatial dataset to explore the nature and strength of spatial autocorrelation. It is essentially a traditional scatter plot in which the variable of interest is displayed against its spatial lag. In order to be able to interpret values as above or below the mean, the variable of interest is usually standardized by subtracting its mean:\n\n\nCalcular o Spatial log\n\n```{python}\n# Calcular o Spatial Lag\n# \ngdf1106[\"w_IND65\"] = weights.lag_spatial(w, gdf1106['IND65'])\n\n# And their respective centered versions, where we subtract the average off of every value\ngdf1106[\"IND65_std\"] = gdf1106[\"IND65\"] - gdf1106[\"IND65\"].mean()\ngdf1106[\"w_IND65_std\"] = weights.lag_spatial(w, gdf1106['IND65_std'])\n```\n\n```{python}\n# Visualizar Valores em Cima e Baixo do Médio\n# Set up the figure and axis\nf, ax = plt.subplots(1, figsize=(6, 6))\n# Plot values\n\nsns.regplot(\n    x=\"IND65_std\", y=\"w_IND65_std\", data=gdf1106, ci=None\n)\nplt.show()\n```\n\nFigura com a relação das vizinhanças (Moran Plot)\n\n**Mesma figura com indicação dos 4 quadrantos**\n\n- LH: Valores na subsecção em baixo do médio, valores circundantes em cima do médio\n- HH: Valores na subsecção em cima do médio, valores circundantes em cima do médio\n- LL: Valores na subsecção em baixo do médio, valores circundantes em baixo do médio\n- HL: Valores na subsecção em cima do médio, valores circundantes em baixo do médio\n\n```{python}\n# Criar os Quadrantos\n# Set up the figure and axis\nf, ax = plt.subplots(1, figsize=(6, 6))\n# Plot values\nsns.regplot(\n    x=\"IND65_std\", y=\"w_IND65_std\", data=gdf1106, ci=None\n)\n\n# Esta Parte demora muito tempo\n\n# Add vertical and horizontal lines (definição valor onde adicionar)\nplt.axvline(0, c=\"k\", alpha=0.5)\nplt.axhline(0, c=\"k\", alpha=0.5)\n\n# Adicionar Text para Cada Quadrant - coordinados Text tendo em conta a distribuição dos dados\nplt.text(0.6, 0.20, \"HH\", fontsize=25, c=\"r\")\nplt.text(0.6, -0.15, \"HL\", fontsize=25, c=\"r\")\nplt.text(-0.2, 0.20, \"LH\", fontsize=25, c=\"r\")\nplt.text(-0.15, -0.15, \"LL\", fontsize=25, c=\"r\")\n\n# Displaby\nplt.show()\n```\n\n### Local Moran's I\n\nCalcular LISA (Local Indicators of Spatial Association) e Visualização Inicial \n\n```{python}\n# https://pysal.org/esda/generated/esda.Moran_Local.html\n# lisa = moran_loc\n# Diferença com Notebook da Formação - dá erro porque os valores são NaN\nfrom splot.esda import lisa_cluster\n# data = \nlisa = esda.moran.Moran_Local(gdf1106['IND65'], w)\n\n# Plotar o mapa de clusters de Moran\nlisa_cluster(lisa, gdf1106, figsize=(9,9))\n```\n\nKernel Estimate Plotting\n\n```{python}\nimport numpy as np\n\n# Valores LISa primeiros 10 registos\nprint(lisa.Is[:10])\n\n# alguns indacores dos valores\nprint(f'''Minimum: {np.min(lisa.Is)}\nMaximum: {np.max(lisa.Is)}\nSTD: {np.std(lisa.Is)}''')\n\n```\n\n```{python}\nimport warnings\n\n# Nao mostrar aviso FutereWarning (não aconselhável)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# Draw KDE line\nax = sns.kdeplot(lisa.Is)\n\n# Add one small bar (rug) for each observation\n# along horizontal axis\nsns.rugplot(lisa.Is, ax=ax)\n\nplt.show()\n```\n\nVisualizações diferentes, mapas com medidas LISA\n\nSignificado dos 4 mapas:\n1. Valor LISA cada polígono (valor lisa.Is)\n2. Valor do quadrante cada área (esdaplot.lisa_cluster, p = 1)\n3. Indicação da significância estatística (lisa.p_sim < 0.05)\n4. Combinação dos anterior 2 (esdaplot.lisa_cluster, p = 0.05)\n\n```{python}\nfrom splot import esda as esdaplot\n\n\n# Set up figure and axes\nf, axs = plt.subplots(nrows=2, ncols=2, figsize=(12, 12))\n# Make the axes accessible with single indexing\naxs = axs.flatten()\n\n# Subplot 1 #\n# Choropleth of local statistics\n# Grab first axis in the figure\nax = axs[0]\n# Assign new column with local statistics on-the-fly\ngdf1106.assign(\n    Is=lisa.Is\n    # Plot choropleth of local statistics\n).plot(\n    column=\"Is\",\n    cmap=\"plasma\",\n    scheme=\"quantiles\",\n    k=5,\n    edgecolor=\"white\",\n    linewidth=0.1,\n    alpha=0.75,\n    legend=True,\n    ax=ax,\n)\n\n# Subplot 2 #\n# Quadrant categories\n# Grab second axis of local statistics\nax = axs[1]\n# Plot Quadrant colors (note to ensure all polygons are assigned a\n# quadrant, we \"trick\" the function by setting significance level to\n# 1 so all observations are treated as \"significant\" and thus assigned\n# a quadrant color\nesdaplot.lisa_cluster(lisa, gdf1106, p=1, ax=ax)\n\n# Subplot 3 #\n# Significance map\n# Grab third axis of local statistics\nax = axs[2]\n#\n# Find out significant observations\nlabels = pd.Series(\n    1 * (lisa.p_sim < 0.05),  # Assign 1 if significant, 0 otherwise\n    index=gdf1106.index  # Use the index in the original data\n    # Recode 1 to \"Significant and 0 to \"Non-significant\"\n).map({1: \"Significant\", 0: \"Non-Significant\"})\n# Assign labels to `gdf1106` on the fly\ngdf1106.assign(\n    cl=labels\n    # Plot choropleth of (non-)significant areas\n).plot(\n    column=\"cl\",\n    categorical=True,\n    k=2,\n    cmap=\"Paired\",\n    linewidth=0.1,\n    edgecolor=\"white\",\n    legend=True,\n    ax=ax,\n)\n\n\n# Subplot 4 #\n# Cluster map\n# Grab second axis of local statistics\nax = axs[3]\n# Plot Quadrant colors In this case, we use a 5% significance\n# level to select polygons as part of statistically significant\n# clusters\nesdaplot.lisa_cluster(lisa, gdf1106, p=0.05, ax=ax)\n\n# Figure styling #\n# Set title to each subplot\nfor i, ax in enumerate(axs.flatten()):\n    ax.set_axis_off()\n    ax.set_title(\n        [\n            \"Local Statistics\",\n            \"Scatterplot Quadrant\",\n            \"Statistical Significance\",\n            \"Moran Cluster Map\",\n        ][i],\n        y=0,\n    )\n# Tight layout to minimize in-between white space\nf.tight_layout()\n\n# Display the figure\nplt.show()\n```\n\nDiferentes contagens (Atributo \"q\")\n\n- Atributo 'q' do Moran Local mostra os valores nos 4 quadrantos\n\n```{python}\n# Criar pd.series do resultado\ncounts = pd.Series(lisa.q).value_counts() # Original: pd.value_counts(lisa.q)\ncounts\n\n# Visualizar os valores do primeiros 10 registos \n\nlisa.q[:10]\n\n# Visualizar o numero de áreas com valores estatitisticamente significante\n\n(lisa.p_sim < 0.05).sum() * 100 / len(lisa.p_sim)\n```\n### Getis and Ord's local statistics\n\n**Outras medidas para representar a autocorrelação espacial (Getis and Ord’s)**\n\n- the G<sup>i</sup>: statistic, which omits the value at a site in its local summary\n- the G<sup>i*</sup>: statistic, which includes the site’s own value in the local summary  \n\n\ncalcular indicadores\n\n```{python}\n# Gi\ngo_i = esda.getisord.G_Local(gdf1106[\"IND65\"], w) # , star=None\n# Gi*\ngo_i_star = esda.getisord.G_Local(gdf1106[\"IND65\"], w, star=True)\n```\n\nvisualizar o resultado\n\n```{python}\ndef g_map(g, db, ax, title):\n    \"\"\"\n    Create a cluster map\n    ...\n\n    Arguments\n    ---------\n    g      : G_Local\n             Object from the computation of the G statistic\n    db     : GeoDataFrame\n             Table aligned with values in `g` and containing\n             the geometries to plot\n    ax     : AxesSubplot\n             `matplotlib` axis to draw the map on\n\n    Returns\n    -------\n    ax     : AxesSubplot\n             Axis with the map drawn\n    \"\"\"\n    ec = \"0.8\"\n\n    # Break observations into significant or not\n    sig = g.p_sim < 0.05\n\n    # Plot non-significant clusters\n    ns = db.loc[sig == False, \"geometry\"]\n    ns.plot(ax=ax, color=\"lightgrey\", edgecolor=ec, linewidth=0.1)\n    # Plot HH clusters\n    hh = db.loc[(g.Zs > 0) & (sig == True), \"geometry\"]\n    hh.plot(ax=ax, color=\"red\", edgecolor=ec, linewidth=0.1)\n    # Plot LL clusters\n    ll = db.loc[(g.Zs < 0) & (sig == True), \"geometry\"]\n    ll.plot(ax=ax, color=\"blue\", edgecolor=ec, linewidth=0.1)\n    # Style and draw\n    contextily.add_basemap(\n        ax,\n        crs=db.crs,\n        source=contextily.providers.Esri.WorldTerrain,\n    )\n    # Flag to add a star to the title if it's G_i*\n    st = \"\"\n    if g.star:\n        st = \"*\"\n    # Add title\n    ax.set_title(f\"G{st} statistic {title}\", size=15)\n    # Remove axis for aesthetics\n    ax.set_axis_off()\n    return ax\n```\n\n```{python}\n# Set up figure and axes\nf, axs = plt.subplots(1, 2, figsize=(12, 6))\n# Loop over the two statistics\nfor g, ax in zip([go_i, go_i_star], axs.flatten()):\n    # Generate the statistic's map\n    ax = g_map(g, gdf1106, ax, 'Rácio Popuação 65+ Anos')\n# Tight layout to minimise blank spaces\nf.tight_layout()\n# Render\nplt.show()\n```\n\n### Exercício\n\n**Repetir o código com outras variáveis e\\ou com município de Porto ou outro município\n\n- Utilizar o codigo Anterior para Calcular para outras variaveis\n    - Lista variáveis: 'IND65','IND14', 'IND_H', 'IND_M','EDIF_3PISOS'\n- Repete a mesma análise para outro municipio\n    - Faz download do gpk de um municipio no link: https://mapas.ine.pt/download/index2021.phtml\n    \n```{python}\n# Caminho para o arquivo GeoPackage do municipio de Valongo\ngpk = r\"data\\geo\\BGRI2021_1315.gpkg\"\n\n# Ler os dados do GeoPackage para um GeoDataFrame\ngdf1315 = gpd.read_file(gpk)\n\n# Calcular Novo Atributo Racio de População 65+ anos\ngdf1315['IND65'] = gdf1315.N_INDIVIDUOS_65_OU_MAIS/gdf1315.N_INDIVIDUOS\n\n# Calcular Outros Atributos de interesse para Analisar: , N_EDIFICIOS_3_OU_MAIS_PISOS, N_INDIVIDUOS_H, N_INDIVIDUOS_M\ngdf1315['IND14'] = gdf1315.N_INDIVIDUOS_0_14/gdf1315.N_INDIVIDUOS\ngdf1315['IND_H'] = gdf1315.N_INDIVIDUOS_H/gdf1315.N_INDIVIDUOS\ngdf1315['IND_M'] = gdf1315.N_INDIVIDUOS_M/gdf1315.N_INDIVIDUOS\ngdf1315['EDIF_3PISOS'] = gdf1315.N_EDIFICIOS_3_OU_MAIS_PISOS/gdf1315.N_EDIFICIOS_CLASSICOS\n\n\n# Mostrar Dados\nprint(gdf1315[['BGRI2021', 'DTMNFR21', 'N_INDIVIDUOS_65_OU_MAIS', 'N_INDIVIDUOS', 'IND65', 'IND14', 'IND_H', 'IND_M','EDIF_3PISOS']].head(10))\n\n\nfrom pysal.model import spreg\n\n# Input gdf1106 (BGRI de Lisboa)\n\n# Calcular a matriz de pesos espaciais\n# Metodo Original: 0.13069266093679838 e Valor-p: 0.001\nw = pysal.lib.weights.Queen.from_dataframe(gdf1315, use_index=True)\n# Metodo knn (I de Moran: 0.11720923169446687; Valor-p: 0.001)\n#w = pysal.lib.weights.KNN.from_dataframe(gdf1106, k=5)\n\n# Lidar com ilhas\n# Normalizar a matriz de pesos\n# Row-standardization \nw.transform = \"r\"\n\n# Corrigir para ilhas\n#w.set_transform('r')\nislands = w.islands\nif islands:\n    for island in islands:\n        w.neighbors[island] = [island]\n        w.weights[island] = [1]  \n        \n# Selecionar a coluna com a percentagem de população superior a 65 anos\ndata = gdf1315['IND65']\n\n\n# Calcular a estatística de Moran\nmoran = esda.Moran(data, w)\n\n# Imprimir o valor I de Moran e o valor-p\nprint('I de Moran:', moran.I)\nprint('Valor-p:', moran.p_sim)\n\n```\n\n\n```{python}\n# Calcular o Spatial Lag\n# \ngdf1315[\"w_IND14\"] = weights.lag_spatial(w, gdf1315['IND14'])\n\n# And their respective centered versions, where we subtract the average off of every value\ngdf1315[\"IND14_std\"] = gdf1315[\"IND14\"] - gdf1315[\"IND14\"].mean()\ngdf1315[\"w_IND14_std\"] = weights.lag_spatial(w, gdf1315['IND14_std'])\n```\n\n```{python}\n#| eval: false\n\n# Visualizar Valores em Cima e Baixo do Médio\n# Set up the figure and axis\nf, ax = plt.subplots(1, figsize=(6, 6))\n# Plot values\n\nsns.regplot(\n    x=\"IND14_std\", y=\"w_IND14_std\", data=gdf1315 ci=None\n)\n\n\n# Criar os Quadrantos\n# Set up the figure and axis\nf, ax = plt.subplots(1, figsize=(6, 6))\n# Plot values\nsns.regplot(\n    x=\"IND14_std\", y=\"w_IND14_std\", data=gdf1315, ci=None\n)\n\n# Esta Parte demora muito tempo\n\n# Add vertical and horizontal lines (definição valor onde adicionar)\nplt.axvline(0, c=\"k\", alpha=0.5)\nplt.axhline(0, c=\"k\", alpha=0.5)\n\n# # Adicionar Text para Cada Quadrant - coordinados Text tendo em conta a distribuição dos dados\n# plt.text(0.6, 0.20, \"HH\", fontsize=25, c=\"r\")\n# plt.text(0.6, -0.15, \"HL\", fontsize=25, c=\"r\")\n# plt.text(-0.2, 0.20, \"LH\", fontsize=25, c=\"r\")\n# plt.text(-0.15, -0.15, \"LL\", fontsize=25, c=\"r\")\n\n# Displaby\nplt.show()\n```\n\n## Clustering e Regionalization\n\n```{python}\nimport matplotlib.pyplot as plt  # Graphics\nfrom matplotlib import colors\nimport seaborn as sns  # Graphics\nimport geopandas as gpd # Spatial data manipulation\nimport pandas as pd  # Tabular data manipulation\nimport numpy as np\n\n# Para Evitar Aviso Point Patterns\nfrom shapely.geometry import Point\nimport contextily  # Background tiles\n\n# Bibliotecas Referidos no Notebook\nfrom esda.moran import Moran\nfrom libpysal.weights import Queen, KNN\n#import pysal.lib # importação geral\nfrom pysal.explore import esda  # Exploratory Spatial analytics\nfrom pysal.lib import weights  # Spatial weights\n\n```\n\npreparação dos dados\n\n```{python}\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\n# Caminho para o arquivo GeoPackage\ngpk = r'data\\geo\\BGRI2021_1106.gpkg'\n\n# Ler os dados do GeoPackage para um GeoDataFrame\ngdf1106 = gpd.read_file(gpk)\n\n# Simplificar a geografia para uma precisão de 5 metros\ngdf1106['geometry'] = gdf1106['geometry'].simplify(tolerance=5)\n\n# Visualizar o GeoDataFrame\ngdf1106.plot(column = 'DTMNFR21',\n              legend = False)\n              \n# Nomes Atributos\n#gdf1106.info()\n\n```\n\n```{python}\n# Incluir os nomes das variáveis que devem ser utilizados para criar os agrupamentos (clusters)\ncluster_variables = [\n    gdf1106.columns[13],  # \n    gdf1106.columns[14],  # \n    gdf1106.columns[15],  # \n    gdf1106.columns[31],  # \n    gdf1106.columns[32],  # \n    gdf1106.columns[37],  # \n    gdf1106.columns[41],  # \n    gdf1106.columns[42],  # E\n    gdf1106.columns[44] # \n]\n```\n\n\n```{python}\n# Tratamento NaN\n# Contar o número total de NaNs no DataFrame\ntotal_nans = gdf1106.isna().sum().sum()\nprint('Número total de registros com NaN:', total_nans)\n\n# Contar o número de NaNs em cada coluna\nnans_por_coluna = gdf1106.isna().sum()\nprint('Número de registros com NaN por coluna:\\n', nans_por_coluna)\n\n# Preencher com valor 0\ngdf1106 = gdf1106.fillna(0)\n```\n\n\n```{python}\n# Mostrar como mapas temáticos os valores dos atributos escolhidos  \n\nf, axs = plt.subplots(nrows=3, ncols=3, figsize=(12, 12))\n# Make the axes accessible with single indexing\naxs = axs.flatten()\n# Start a loop over all the variables of interest\nfor i, col in enumerate(cluster_variables):\n    # select the axis where the map will go\n    ax = axs[i]\n    # Plot the map\n    gdf1106.plot(\n        column=col,\n        ax=ax,\n        scheme=\"Quantiles\",\n        linewidth=0,\n        cmap=\"RdPu\",\n    )\n    # Remove axis clutter\n    ax.set_axis_off()\n    # Set the axis title to the name of variable being plotted\n    ax.set_title(col)\n# Display the figure\nplt.show()\n```\n\n\nCalcular Moran I para todas as variáveis\n\n```{python}\n# Generate W from the GeoDataFrame\n# w = weights.distance.KNN.from_dataframe(gdf1106, k=8)\n# Metodo Alternativo:\nw = weights.Queen.from_dataframe(gdf1106, use_index=True)\n```\n\n```{python}\n# Set seed for reproducibility\nnp.random.seed(123456)\n# Calculate Moran's I for each variable\nmi_results = [\n    Moran(gdf1106[variable], w) for variable in cluster_variables\n    ]\n# Structure results as a list of tuples\nmi_results = [\n    (variable, res.I, res.p_sim)\n    for variable, res in zip(cluster_variables, mi_results)\n]\n# Display on table\ntable = pd.DataFrame(\n    mi_results, columns=[\"Variable\", \"Moran's I\", \"P-value\"]\n).set_index(\"Variable\")\ntable\n```\n\n```{python}\n# Utilizar kdeplot dá um aviso\nimport warnings\n\n# Nao mostrar aviso FutereWarning (não aconselhável)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# Mostrar kdeplot para cada variável\n# _: Convenção Python que mostra que o resultado não está a ser utilizado\n\nsns.pairplot(\n    gdf1106[cluster_variables], kind=\"reg\", diag_kind=\"kde\"\n)\n```\n\n```{python}\n# The distance between observations in terms of these variates can be computed easily using\nfrom sklearn import metrics\nmetrics.pairwise_distances(\n    gdf1106[[cluster_variables[0], cluster_variables[5]]].head()\n).round(4)\n\n```\n\n```{python}\nfrom sklearn.preprocessing import robust_scale\n# And create the db_scaled object which contains only the variables we are interested in, scaled:\ndb_scaled = robust_scale(gdf1106[cluster_variables])\nprint(type(db_scaled))\n```\n\n### Cluster GeoDemograficos\n\n### K-means\n\n```{python}\n# Initialize KMeans instance\nfrom sklearn.cluster import KMeans\n\n# Initialize KMeans instance\n# Definir n_init explicitemente\nkmeans = KMeans(n_clusters=5,n_init=10)\n\n# Set the seed for reproducibility\nnp.random.seed(1234)\n# Run K-Means algorithm\nk5cls = kmeans.fit(db_scaled)\n\n# Print first five labels\nk5cls.labels_[:5]\n```\n\nvisualização dos resultados\n\n```{python}\n# Assign labels into a column\ngdf1106[\"k5cls\"] = k5cls.labels_\n# Set up figure and ax\nf, ax = plt.subplots(1, figsize=(9, 9))\n# Plot unique values choropleth including\n# a legend and with no boundary lines\ngdf1106.plot(\n    column=\"k5cls\", categorical=True, legend=True, linewidth=0, ax=ax,\n    legend_kwds={'loc': 'upper left'}\n)\n# Remove axis\nax.set_axis_off()\n# Display the map\nplt.show()\n```\n\nAnálise dos resultados obtidos\n\n```{python}\n# Group data table by cluster label and count observations\nk5sizes = gdf1106.groupby(\"k5cls\").size()\nk5sizes\n```\n\nobter a área de cada grupo (dissolve) utilizando o atributo SHAPE_Area\n\n```{python}\n# Dissolve areas by Cluster, aggregate by summing,\n# and keep column for area\nareas = gdf1106.dissolve(by=\"k5cls\", aggfunc=\"sum\")[\"SHAPE_Area\"]\nareas\n```\n\nnº de elementos _vs_ área de cada grupo\n\n```{python}\n# Visualizar o nº de elementos vs a Área total\n\n# Bind cluster figures in a single table\narea_tracts = pd.DataFrame({\"No. Tracts\": k5sizes, \"Area\": areas})\n# Convert raw values into percentages\narea_tracts = area_tracts * 100 / area_tracts.sum()\n# Bar plot\nax = area_tracts.plot.bar()\n# Rename axes\nax.set_xlabel(\"Cluster labels\")\nax.set_ylabel(\"Percentage by cluster\")\n\nplt.show()\n\n```\n\n**Criar um perfil de cada cluster, executamos as seguintes tarefas:**\n\n1. Calcular os médios de cada variável\n2. Arrumar (tidy up) os dados, assegurando que cada linha é uma observação e cada coluna é uma variável  \n3. Visualizar a distribuição dos valores das variáveis por grupo\n\n```{python}\n# Criar os Perfis de cada Cluster em relação as variáveis de input\n# Mostrar os médios das variáveis em cada cluster\n# Group table by cluster label, keep the variables used\n# for clustering, and obtain their mean\nk5means = gdf1106.groupby(\"k5cls\")[cluster_variables].mean()\n# Transpose the table and print it rounding each value\n# to three decimals\nk5means.T.round(3)\n```\n\n\n```{python}\n# Index db on cluster ID\ntidy_db = gdf1106.set_index(\"k5cls\")\n# Keep only variables used for clustering\ntidy_db = tidy_db[cluster_variables]\n# Stack column names into a column, obtaining\n# a \"long\" version of the dataset\ntidy_db = tidy_db.stack()\n# Take indices into proper columns\ntidy_db = tidy_db.reset_index()\n# Rename column names\ntidy_db = tidy_db.rename(\n    columns={\"level_1\": \"Attribute\", 0: \"Values\"}\n)\n# Check out result\ntidy_db.head()\n```\n\n```{python}\n# hows the distribution of each cluster’s values for each variable. \n# This gives us the full distributional profile of each cluster:\n# Scale fonts to make them more readable\nsns.set(font_scale=1.5)\n# Setup the facets\nfacets = sns.FacetGrid(\n    data=tidy_db,\n    col=\"Attribute\",\n    hue=\"k5cls\",\n    sharey=False,\n    sharex=False,\n    aspect=2,\n    col_wrap=3,\n)\n# Build the plot from `sns.kdeplot`\nfacets.map(sns.kdeplot, \"Values\", shade=True).add_legend()\n```\n\n### Hierarchical Clustering\n\n```{python}\nfrom sklearn.cluster import AgglomerativeClustering\n\n# Set seed for reproducibility\nnp.random.seed(0)\n# Initialize the algorithm\nmodel = AgglomerativeClustering(linkage=\"ward\", n_clusters=5)\n# Run clustering (input dataset é sempre o db_scaled com valores estandarizados)\nmodel.fit(db_scaled)\n# Assign labels to main data table\ngdf1106[\"ward5\"] = model.labels_\n\nward5sizes = gdf1106.groupby(\"ward5\").size()\nward5sizes\n```\n\nvisualizar dados\n\n```{python}\n# Index db on cluster ID\ntidy_db = gdf1106.set_index(\"ward5\")\n# Keep only variables used for clustering\ntidy_db = tidy_db[cluster_variables]\n# Stack column names into a column, obtaining\n# a \"long\" version of the dataset\ntidy_db = tidy_db.stack()\n# Take indices into proper columns\ntidy_db = tidy_db.reset_index()\n# Rename column names\ntidy_db = tidy_db.rename(\n    columns={\"level_1\": \"Attribute\", 0: \"Values\"}\n)\n# Check out result\ntidy_db.head()\n```\n\n```{python}\n# Setup the facets\nfacets = sns.FacetGrid(\n    data=tidy_db,\n    col=\"Attribute\",\n    hue=\"ward5\",\n    sharey=False,\n    sharex=False,\n    aspect=2,\n    col_wrap=3,\n)\n# Build the plot as a `sns.kdeplot`\nfacets.map(sns.kdeplot, \"Values\", shade=True).add_legend()\n```\n\ncomparação dos 2 resultados  \n```{python}\ngdf1106[\"ward5\"] = model.labels_\n# Set up figure and ax\nf, axs = plt.subplots(1, 2, figsize=(12, 6))\n\n### K-Means ###\nax = axs[0]\n# Plot unique values choropleth including\n# a legend and with no boundary lines\ngdf1106.plot(\n    column=\"ward5\",\n    categorical=True,\n    cmap=\"Set3\",\n    legend=True,\n    linewidth=0,\n    ax=ax,\n    legend_kwds={'loc': 'upper left'}\n)\n# Remove axis\nax.set_axis_off()\n# Add title\nax.set_title(\"K-Means solution ($k=5$)\")\n\n### AHC ###\nax = axs[1]\n# Plot unique values choropleth including\n# a legend and with no boundary lines\ngdf1106.plot(\n    column=\"k5cls\",\n    categorical=True,\n    cmap=\"Set3\",\n    legend=True,\n    linewidth=0,\n    ax=ax,\n    legend_kwds={'loc': 'upper left'}\n)\n# Remove axis\nax.set_axis_off()\n# Add title\nax.set_title(\"AHC solution ($k=5$)\")\n\n# Display the map\nplt.show()\n```\n\n\n### Regionalization\n\nCriar novos Cluster\n\n+ Incluir matriz de vizinhança\n+ connectivity = w.sparse\n\n```{python}\n# Set the seed for reproducibility\nnp.random.seed(123456)\n# Specify cluster model with spatial constraint\nmodel = AgglomerativeClustering(\n    linkage=\"ward\", connectivity=w.sparse, n_clusters=5\n)\n# Fit algorithm to the data\nmodel.fit(db_scaled)\n```\n\nvisualizar resultados\n\n```{python}\n\ngdf1106[\"ward5wq\"] = model.labels_\n# Set up figure and ax\nf, ax = plt.subplots(1, figsize=(9, 9))\n# Plot unique values choropleth including a legend and with no boundary lines\ngdf1106.plot(\n    column=\"ward5wq\",\n    categorical=True,\n    legend=True,\n    linewidth=0,\n    ax=ax,\n    legend_kwds={'loc': 'upper left'}\n)\n# Remove axis\nax.set_axis_off()\n# Display the map\nplt.show()\n\n# Guardar o mapa:\nf.savefig(r\"data\\geo\\mapa_clusters1.png\")\n```\n\nRepetir o processo com outra matriz de vizinhança\n\n```{python}\n# Generate W from the GeoDataFrame\nw = weights.distance.KNN.from_dataframe(gdf1106, k=8)\n# Metodo Alternativo:\n#w = weights.Queen.from_dataframe(gdf1106, use_index=True)\n```\n\n### Outros metodos\n\nMedida *compactness*\n\n```{python}\n#| eval: false\nresults = []\nfor cluster_type in (\"k5cls\", \"ward5\", \"ward5wq\", \"ward5wknn\"):\n    # compute the region polygons using a dissolve\n    regions = db[[cluster_type, \"geometry\"]].dissolve(by=cluster_type)\n    # compute the actual isoperimetric quotient for these regions\n    ipqs = (\n        regions.area * 4 * numpy.pi / (regions.boundary.length ** 2)\n    )\n    # cast to a dataframe\n    result = ipqs.to_frame(cluster_type)\n    results.append(result)\n# stack the series together along columns\npandas.concat(results, axis=1)\n```\n\n\n```{python}\nimport numpy\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport geopandas as gpd\n\n# gdf1106['IND65'] = gdf1106.N_INDIVIDUOS_65_OU_MAIS/gdf1106.N_INDIVIDUOS\ngdf1106['compact'] = gdf1106.geometry.area * 4  * numpy.pi / (gdf1106.geometry.boundary.length ** 2)\n\n# Definir Legenda \nlgnd_kwds = {'loc': 'upper left', \n             'bbox_to_anchor': (1, 1.03), \n             'ncol': 3}\n\n# Generate the choropleth and store the axis\n# natural_breaks\nax = gdf1106.plot(column='compact', \n                      scheme='quantiles', # natural_breaks, quantiles, equal_interval \n                      k=9, \n                      cmap='PuBu', \n                      legend=True,\n                      edgecolor = 'None', # sem outline\n                      legend_kwds  = lgnd_kwds)\n \n# Remover frames, ticks e tick labels do axis\nax.set_axis_off()\n\nplt.title('Compactness')\nplt.show()\n```\n\n```{python}\nprint(gdf1106.head())\n```\n\nKriging com o *package* `pykrige`\n\n```{python}\nimport numpy as np\nfrom pykrige.ok import OrdinaryKriging\nimport pykrige.kriging_tools as kt\nimport matplotlib.pyplot as plt  \n\n# Sample data points\ndata = np.array(\n    [\n        [0.3, 1.2, 0.5],\n        [1.1, 3.2, 0.4],\n        [1.8, 0.8, 0.6],\n        [2.8, 2.6, 0.7],\n        [3.2, 0.3, 0.8],\n    ]\n)  # [x, y, z]\n\n# Define the grid to interpolate onto\ngridx = np.arange(0.0, 4.1, 0.1)\ngridy = np.arange(0.0, 4.1, 0.1)\n\n# Create an Ordinary Kriging object\nOK = OrdinaryKriging(\n    data[:, 0],  # X coordinates\n    data[:, 1],  # Y coordinates\n    data[:, 2],  # Z values\n    variogram_model=\"spherical\",  # Variogram model (can also use \"linear\" gaussian\" or \"spherical\")\n    verbose=False,\n    enable_plotting=True,  # Enable plotting of the variogram (optional)\n)\n\n# Execute Ordinary Kriging on the defined grid\n# `z` contains the interpolated values\n# `ss` contains the standard deviation at each grid point\nz, ss = OK.execute(\"grid\", gridx, gridy)\n\n# Writes the kriged grid to an ASCII grid file and plot it.\nkt.write_asc_grid(gridx, gridy, z, filename=\"data\\geo\\output.asc\")\nplt.imshow(z)\nplt.show()\n\n```\n\n![](images\\geo_predict.png)\n\n### Exercício\n\nadaptar o código anterior para outro municipio\n\n\npreparação dos dados\n\n```{python}\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\n# Caminho para o arquivo GeoPackage municipio Valongo\ngpk = r'data\\geo\\BGRI2021_1315.gpkg'\n\n# Ler os dados do GeoPackage para um GeoDataFrame\ngdf1315 = gpd.read_file(gpk)\n\n# Simplificar a geografia para uma precisão de 5 metros\ngdf1315['geometry'] = gdf1315['geometry'].simplify(tolerance=5)\n\n# # Visualizar o GeoDataFrame\n# gdf1315.plot(column = 'DTMNFR21',\n#               legend = False)\n              \n# Nomes Atributos\ngdf1315.info()\n\n```\n\n```{python}\n# Incluir os nomes das variáveis que devem ser utilizados para criar os agrupamentos (clusters)\ncluster_variables = [\n    gdf1315.columns[24],  # \n    gdf1315.columns[25],  # \n    gdf1315.columns[26],  # \n    gdf1315.columns[27],  # \n    gdf1315.columns[28],\n    gdf1315.columns[38],\n    gdf1315.columns[39],\n    gdf1315.columns[40]\n]\n```\n\n\n```{python}\n# Tratamento NaN\n# Contar o número total de NaNs no DataFrame\ntotal_nans = gdf1315.isna().sum().sum()\nprint('Número total de registros com NaN:', total_nans)\n\n# Contar o número de NaNs em cada coluna\nnans_por_coluna = gdf1315.isna().sum()\nprint('Número de registros com NaN por coluna:\\n', nans_por_coluna)\n\n# Preencher com valor 0\ngdf1315 = gdf1315.fillna(0)\n```\n\n\n```{python}\n# Mostrar como mapas temáticos os valores dos atributos escolhidos  \n\nf, axs = plt.subplots(nrows=3, ncols=3, figsize=(12, 12))\n# Make the axes accessible with single indexing\naxs = axs.flatten()\n# Start a loop over all the variables of interest\nfor i, col in enumerate(cluster_variables):\n    # select the axis where the map will go\n    ax = axs[i]\n    # Plot the map\n    gdf1315.plot(\n        column=col,\n        ax=ax,\n        scheme=\"Quantiles\",\n        linewidth=0,\n        cmap=\"RdPu\",\n    )\n    # Remove axis clutter\n    ax.set_axis_off()\n    # Set the axis title to the name of variable being plotted\n    ax.set_title(col)\n# Display the figure\nplt.show()\n```\n\n\nCalcular Moran I para todas as variáveis\n\n```{python}\n# Generate W from the GeoDataFrame\n# w = weights.distance.KNN.from_dataframe(gdf1315, k=8)\n# Metodo Alternativo:\nw = weights.Queen.from_dataframe(gdf1315, use_index=True)\n```\n\n```{python}\n# Set seed for reproducibility\nnp.random.seed(123456)\n# Calculate Moran's I for each variable\nmi_results = [\n    Moran(gdf1315[variable], w) for variable in cluster_variables\n    ]\n# Structure results as a list of tuples\nmi_results = [\n    (variable, res.I, res.p_sim)\n    for variable, res in zip(cluster_variables, mi_results)\n]\n# Display on table\ntable = pd.DataFrame(\n    mi_results, columns=[\"Variable\", \"Moran's I\", \"P-value\"]\n).set_index(\"Variable\")\ntable\n```\n\n```{python}\n# Utilizar kdeplot dá um aviso\nimport warnings\n\n# Nao mostrar aviso FutereWarning (não aconselhável)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# Mostrar kdeplot para cada variável\n# _: Convenção Python que mostra que o resultado não está a ser utilizado\n\nsns.pairplot(\n    gdf1315[cluster_variables], kind=\"reg\", diag_kind=\"kde\"\n)\n```\n\n```{python}\n# The distance between observations in terms of these variates can be computed easily using\nfrom sklearn import metrics\nmetrics.pairwise_distances(\n    gdf1315[[cluster_variables[0], cluster_variables[5]]].head()\n).round(4)\n\n```\n\n```{python}\nfrom sklearn.preprocessing import robust_scale\n# And create the db_scaled object which contains only the variables we are interested in, scaled:\ndb_scaled = robust_scale(gdf1315[cluster_variables])\nprint(type(db_scaled))\n```\n\n\n\n```{python}\nimport numpy\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport geopandas as gpd\n\n# gdf1106['IND65'] = gdf1106.N_INDIVIDUOS_65_OU_MAIS/gdf1106.N_INDIVIDUOS\ngdf1315['compact'] = gdf1315.geometry.area * 4  * numpy.pi / (gdf1315.geometry.boundary.length ** 2)\n\n# Definir Legenda \nlgnd_kwds = {'loc': 'upper left', \n             'bbox_to_anchor': (1, 1.03), \n             'ncol': 3}\n\n# Generate the choropleth and store the axis\n# natural_breaks\nax = gdf1315.plot(column='compact', \n                      scheme='quantiles', # natural_breaks, quantiles, equal_interval \n                      k=9, \n                      cmap='PuBu', \n                      legend=True,\n                      edgecolor = 'None', # sem outline\n                      legend_kwds  = lgnd_kwds)\n \n# Remover frames, ticks e tick labels do axis\nax.set_axis_off()\n\nplt.title('Compactness')\nplt.show()\n```\n\n```{python}\nprint(gdf1315.head())\n```\n\nKriging com o *package* `pykrige`\n\n```{python}\nimport numpy as np\nfrom pykrige.ok import OrdinaryKriging\nimport pykrige.kriging_tools as kt\nimport matplotlib.pyplot as plt  \n\n# Sample data points\ndata = np.array(\n    [\n        [0.3, 1.2, 0.5],\n        [1.1, 3.2, 0.4],\n        [1.8, 0.8, 0.6],\n        [2.8, 2.6, 0.7],\n        [3.2, 0.3, 0.8],\n    ]\n)  # [x, y, z]\n\n# Define the grid to interpolate onto\ngridx = np.arange(0.0, 4.1, 0.1)\ngridy = np.arange(0.0, 4.1, 0.1)\n\n# Create an Ordinary Kriging object\nOK = OrdinaryKriging(\n    data[:, 0],  # X coordinates\n    data[:, 1],  # Y coordinates\n    data[:, 2],  # Z values\n    variogram_model=\"spherical\",  # Variogram model (can also use \"linear\" gaussian\" or \"spherical\")\n    verbose=False,\n    enable_plotting=True,  # Enable plotting of the variogram (optional)\n)\n\n# Execute Ordinary Kriging on the defined grid\n# `z` contains the interpolated values\n# `ss` contains the standard deviation at each grid point\nz, ss = OK.execute(\"grid\", gridx, gridy)\n\n# Writes the kriged grid to an ASCII grid file and plot it.\nkt.write_asc_grid(gridx, gridy, z, filename=\"data\\geo\\output.asc\")\nplt.imshow(z)\nplt.show()\n\n```\n\n## JSON / API INE\n\n### JavaScript Object Notation\n\n+ formato de dados leve e eficiente\n+ dados estruturados\n+ amplamente utilizado\n\nútil para:\n\n+ recolha de dados\n+ preparação de dados\n+ análise de dados\n+ visualização de dados\n\nJSON _vs_ XML\n\n![](images\\json_xml.png)\n\nUm objecto JSON é um conjunto de pares de chave e valor encerrados por chaves.\n\n_packages_ python para ler JSON: `json`, `pandas`, `requests`, `jsonpath-ng`, `jsonschema` \n\n```{python}\n# Ler JSON de um Dicionario\nimport pprint # para visualizar de forma mais amigavel os dados\nimport json\n\n# Criar um Dictionary (exemplo dados municipios)\nmunicipios = {\n    \"Almada\": {\n        \"populacao\": 177400        \n    },\n    \"Cascais\": {\n        \"populacao\": 214124        \n    },\n    \"Seixal\": {\n        \"populacao\": 160000\n    },\n    \"Entroncamento\": {\n        \"populacao\": 20141\n    },\n    \"Cadaval\": {\n        \"populacao\": 13372\n    },\n    \"Sintra\": {\n        \"populacao\": 385606\n    }\n}\n\nprint(type(municipios))\n\n# Converter o Dictionary para uma string JSON\nmn_json = json.dumps(municipios)\nprint(type(mn_json))\n\n# Fazer Load do JSON\ndata_json = json.loads(mn_json)\nprint(type(data_json))\n\n# Mostrar População Cascais\nprint (\"População Cascais:\",data_json[\"Cascais\"][\"populacao\"])\n\n# Imprimir o Type do Object Devolvido\nprint('Tipo Objecto:', type(data_json))\n\n# Imprimir o objecto com PrettyPrinter\npp = pprint.PrettyPrinter(indent=2)\n\n# Imprimir o dicionário\npp.pprint(data_json)\n```\n\n```{python}\n# Criar JSOn a partir de uma Listagem:\n# import json\n# import pprint\n\n# Exemplo cidades de Portugal\ncidades = [\"Lisboa\", \"Porto\", \"Vila Nova de Gaia\", \"Amadora\", \"Braga\", \"Funchal\", \"Coimbra\", \"Almada\", \"Setúbal\", \"Agualva-Cacém\"]\n\n# Converter a lista para uma string JSON\ncidades_json = json.dumps(cidades)\nprint('Tipo Objecto após json.dumps:', type(cidades_json))\n\n# Converter a string JSON de volta para uma lista\ndata_json = json.loads(cidades_json)\n\n\n# Imprimir o Type do Object Devolvido\nprint('Tipo Objecto após json.loads:', type(data_json))\n\n# Imprimir os dados carregados\n# Criar um objeto PrettyPrinter\npp = pprint.PrettyPrinter(indent=4)\n\n# Imprimir o dicionário\npp.pprint(data_json)\n\n```\n\nler dados de um ficheiro\n\n```{python}\n# exemplo de um ficheiro com os municipios de Madrid\nimport json\nimport pandas as pd\n# Ler Dados de um Ficheiro no computador (Municipios de Provincia de Madrid)\njsonfile = r\"data\\geo\\municipio_comunidad_madrid.json\"\n\n# Abrir Ficheiro e fazer Load\nwith open(jsonfile, 'r') as f:\n    json_data = json.load(f)\n\nprint(type(json_data))\n    \n# Verificar Tipo de Dados Devolvido e mostrar informação\nif isinstance(json_data, list):\n    print(\"JSON object is a list.\")\n    if json_obj:\n        print(\"Numero Registos:\", len(json_data))\n        print(\"Registo Exemplo:\", json_data[0])\nelif isinstance(json_data, dict):\n    print(\"JSON object is a dictionary.\")\n    print(\"Keys do Object:\", list(json_data.keys()))\nelse:\n    print(\"Unknown JSON object type.\")\n\nnovoelem = json_data[\"data\"]  \nprint (type(novoelem))\n\ndf = pd.DataFrame(novoelem)\nprint(df.info())\n\n```\n\nler dados de um URL\n\n```{python}\nimport json\nimport requests\n\nproxies = {\n  'http': 'http://proxy.ine.pt:8080',\n  'https': 'http://proxy.ine.pt:8080',\n}\n\n\nurl = \"https://datos.comunidad.madrid/catalogo/dataset/032474a0-bf11-4465-bb92-392052962866/resource/301aed82-339b-4005-ab20-06db41ee7017/download/municipio_comunidad_madrid.json\"\n\n# Make an HTTP GET request to fetch the JSON data from the URL\n# \nresponse = requests.get(url)#, proxies=proxies)\n\n# Verificar Resposta\n# Respostas Possiveis\nif response.status_code == 200:\n    #Obter JSON response\n    json_data = response.json()\nelse:\n    print(\"Failed to fetch data. Status code:\", response.status_code)\n    exit()\n\n\n# Verificar Tipo de Dados Devolvido e mostrar informação\nif isinstance(json_data, list):\n    print(\"JSON object is a list.\")\n    if json_data:\n        print(\"Numero Registos:\", len(json_data))\n        print(\"Registo Exemplo:\", json_data[0])\nelif isinstance(json_data, dict):\n    print(\"JSON object is a dictionary.\")\n    print(\"Keys do Object:\", list(json_data.keys()))\nelse:\n    print(\"Unknown JSON object type.\")\n```\n\n### converter para pandas DataFrame\n\nler dados de uma listagem normal  \n```{python}\n  import pandas as pd\n# Ler Informacao JSOn Municipios:\ndf_mn = pd.read_json(r'data\\geo\\municipios.json')\n\nprint(df_mn.info())\nprint('Primeiro Municipio',df_mn['municipio'][0])\n```\n\nnested data  \n```{python}\nimport pandas as pd\n# Ler Informacao JSOn Municipios:\ndf_frmn = pd.read_json(r\"data\\geo\\municipiosfreguesias.json\")\nprint(df_frmn.info())\nprint('Primeiro Municipio',df_frmn['municipio'][0])\n\n# Ver o tipo do atributo freguesias - Series\nprint(type(df_frmn['freguesias']))\n\n# Selecionar o primeiro municipio\ndf_frmn = df_frmn.loc[df_frmn['municipio'] == 'Almada']\n\n# Mostrar os valores das freguesias\nprint(df_frmn['freguesias'])\n\n```\n\nutilizar `json_normalize()`  \n```{python}\n# Utilizar a funcao json_normalize para criar um DF apenas das freguesias\n\n# Load the JSON file\nwith open(r\"data\\geo\\municipiosfreguesias.json\", \"r\", encoding=\"utf-8\") as f:\n    municipalities = json.load(f)\n\n# Convert the JSON into a DataFrame\ndf = pd.json_normalize(municipalities, record_path=['freguesias'])\n\n# Print the DataFrame\nprint(df)\nprint(df.info())\n```\n\n\ncriar dataframe utilizando um loop  \n```{python}\n# Alternativa para criar Informação das Freguesias\n# Ler os dados\nwith open(r\"data\\geo\\municipiosfreguesias.json\", \"r\", encoding=\"utf-8\") as f:\n    municipalities = json.load(f)\n    \n# Criar Lista das linhas do INPUT\nrows = []\n\n# Percorrer os municipios\nfor municipality in municipalities:\n    # Iterate over the freguesias\n    for freguesia in municipality['freguesias']:\n        # Criar novo registo\n        row = {\n            'municipio': municipality['municipio'],\n            'freguesia': freguesia['nome'],\n            'populacao': freguesia['populacao']\n        }\n\n        # Adicionar Registo a Lista\n        rows.append(row)\n\n# Criar DataFame\ndf = pd.DataFrame(rows)\n\n# Print the DataFrame\nprint(df)\n```\n\n### Exercício\n\n**A partir do objecto pt_info**\n\n1. Converter o dicionário para uma string JSON  \n2. Converter a string JSON de volta para um dicionário\n3. Obter o tipo do objecto devolvido\n4. Imprimir as chaves\n5. Converter para DataFrame\n6. Fazer algumas pesquisas\n\n    - População de Vila Nova de Gaia\n    - Area de Portugal\n    \n```{python}\n# Dictionary com informcao Portugal:\n# Também é Nested\npt_info = {\n  \"country\": \"Portugal\",\n  \"capital\": \"Lisbon\",\n  \"population\": 10347892,\n  \"area\": 92212,\n  \"language\": \"Portuguese\",\n  \"currency\": \"Euro\",\n  \"cities\": [\n    {\n      \"name\": \"Lisbon\",\n      \"population\": 504762,\n      \"region\": \"Lisboa\"\n    },\n    {\n      \"name\": \"Porto\",\n      \"population\": 219419,\n      \"region\": \"Norte\"\n    },\n    {\n      \"name\": \"Vila Nova de Gaia\",\n      \"population\": 301877,\n      \"region\": \"Norte\"\n    },\n    {\n      \"name\": \"Matosinhos\",\n      \"population\": 174339,\n      \"region\": \"Norte\"\n    },\n    {\n      \"name\": \"Almada\",\n      \"population\": 174033,\n      \"region\": \"Lisboa\"\n    }\n  ]\n}\n\nprint(type(pt_info))\n```\n\n```{python}\n# Converter o Dictionary para uma string JSON\nmn_json = json.dumps(pt_info)\nprint(type(mn_json))\n\n# Fazer Load do JSON\ndata_json = json.loads(mn_json)\nprint(type(data_json))\n\n# Imprimir o Type do Object Devolvido\nprint('Tipo Objecto:', type(data_json))\n\n# Imprimir o objecto com PrettyPrinter\npp = pprint.PrettyPrinter(indent=2)\n\n# Imprimir o dicionário\npp.pprint(data_json)\n\n# Obter o Nome da primeira cidade \nprint(data_json['cities'][0]['name'])\n\n# população do Porto\nprint('População do Porto: ',data_json['cities']['name' == 'Porto']['population'])\n\n# 4. Imprimir as chaves \n# Verificar Tipo de Dados Devolvido e mostrar informação\nif isinstance(data_json, list):\n    print(\"JSON object is a list.\")\n    if json_obj:\n        print(\"Numero Registos:\", len(data_json))\n        print(\"Registo Exemplo:\", data_json[0])\nelif isinstance(data_json, dict):\n    print(\"JSON object is a dictionary.\")\n    print(\"Keys do Object:\", list(data_json.keys()))\nelse:\n    print(\"Unknown JSON object type.\")\n\n# 5. Converter para DataFrame\ndf = pd.json_normalize(data_json, record_path=['cities'])\nprint(df)\n\n\n# 6. Fazer algumas pesquisas\n#  - População de Vila Nova de Gaia\n#  - Area de Portugal\npopulacao_vila_nova_de_gaia = df[df['name'] == 'Vila Nova de Gaia']['population'].values[0]\nprint(\"População de Vila Nova de Gaia:\", populacao_vila_nova_de_gaia)\n\narea_portugal = data_json['area']\nprint(\"Área de Portugal:\", area_portugal)\n\n```\n\n## JSON INE\n\n```{python}\nimport requests\nimport os\n# Ler Dados Inicial para JSON\n# Indicador 0008074: Taxa de criminalida, último ano, todos os níveis geográficos, indicador \n# Categorias no SMI do Dim3: http://smi-i.ine.pt/Versao/Detalhes/902 \nproxies = {\n  'http': 'http://proxy.ine.pt:8080',\n  'https': 'http://proxy.ine.pt:8080',\n}\n\n# os.environ['http_proxy'] = 'http://proxy.ine.pt:8080'\n# os.environ['https_proxy'] = 'http://proxy.ine.pt:8080'\n\n# Dim1=T: Dados de todos os anos\nurl = \"https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=0008074&Dim1=T&Dim3=3&lang=PT\"\nprint(url)\n# Make an HTTP GET request to fetch the JSON data from the URL\nresponse = requests.get(url)#, proxies=proxies)\n\n# Verificar Resposta\n# Respostas Possiveis\nif response.status_code == 200:\n    #Obter JSON response\n    json_data = response.json()\nelse:\n    print(\"Failed to fetch data. Status code:\", response.status_code)\n    exit()\n\n\n# Verificar Tipo de Dados Devolvido e mostrar informação\nif isinstance(json_data, list):\n    print(\"JSON object is a list.\")\n    if json_data:\n        print(\"Numero Registos:\", len(json_data))\n        #print(\"Registo Exemplo:\", json_data[0])\n        print(\"Tipo 1º elementos:\", type(json_data[0]))\nelif isinstance(json_data, dict):\n    print(\"JSON object is a dictionary.\")\n    print(\"Keys do Object:\", list(json_data.keys()))\nelse:\n    print(\"Unknown JSON object type.\")\n\n    \n# Obter tipo de keys no dictionary\nprint(\"Keys existentes:\", list(json_data[0].keys()))\n\n# Key com os dados\n```\n\nanalisar o objecto JSON devolvido  \n```{python}\n# Para poder Importar será necessário de fazer uma análise do Objeto Devolvido\n\n# Obter Keys no Dados\n# Existe um Key para Cada Ano\nprint(\"Keys existentes nos Dados:\", list(json_data[0]['Dados'].keys()) )\n\n# Ver Tipo de conteudo 2022:\nprint(\"Tipo Objecto:\", type(json_data[0]['Dados']['2022']) )\n\n# Tipo é Listagem de Dictionary's\n# Ver conteudo e informação 1º elemento\nprint(\"Tipo primeiro elemento:\", type(json_data[0]['Dados']['2022'][0]), 'Numero Elementos:', len(json_data[0]['Dados']['2022']) )\n# Atributos de cada dictionary\nprint(\"Keys existentes no Ano:\", list(json_data[0]['Dados']['2022'][0].keys()) )\n```\nmostrar ano  \n```{python}\n# Fazer um Loop por todos os anos\nfor ky in list(json_data[0]['Dados'].keys()):\n    print(ky)\n```\n\ncriar dataframe dos dados   \n```{python}\nimport geopandas as gpd\n\ndadosmn = r\"data\\geo\\GPK_CAOP_MN.gpkg\"\n# Ler os dados do GeoPackage para um GeoDataFrame\ngdfmn = gpd.read_file(dadosmn, encoding='utf-8')\nprint(gdfmn.info())\nprint(gdfmn.head())\n```\n\n\n```{python}\nimport pandas as pd\n# Os dados para importar dzem respeito a uma listagem de dictionary's. \n\n# Os dados podem ser importados a partir destas listagem com função pd.DataFrame()\n# Para assegurar o tipo de dados deveria ser especificado o tipo de atributos das colunas \ncolumns = [\"geocod\", \"geodsg\", \"dim_3\", \"dim_3_t\", \"valor\"]\ndata_types = {\"geocod\": str, \"geodsg\": str, \"dim_3\": str, \"dim_3_t\": str, \"valor\": float}\n\n# Convert the list of dictionaries to a Pandas DataFrame\ndf_ine = pd.DataFrame(json_data[0]['Dados']['2022'], columns=columns).astype(data_types)\n\n# Mostrar o Resultado:\nprint(df_ine.info())\nprint(df_ine.head(8))\nprint('Numero registos:',len(df_ine))\n\n# Novo Cell - filter NUTS3 (length geocod == 3):\n# Alternativa - seria criar uma listagem unica a 34]\ndf_nuts3 = df_ine[df_ine['geocod'].str.len() == 3]\nprint(df_nuts3.info())\n\n#df_nuts3['codmn'] = df_nuts3['geocod'].str[-4:]\n# df_nuts3['geocod'].str[-4:]\n#print(df_nuts3.head(10))\n\n# df_mn = df_ine[df_ine['geocod'].str.len() == 7]\n# print(df_mn.info())\n# df_mn['codmn'] = df_mn['geocod'].str[-4:]\n# print(df_mn.head(10))\n\n```\n\nvisualizar os dados como um mapa  \n```{python}\n# Mostrar valores unicos chave\nimport numpy as np\nprint(np.sort(df_nuts3.geocod.unique()))\nprint(df_nuts3[['geocod','geodsg','valor']])\n\n# Corrigir Valores NaN\ndf_nuts3 = df_nuts3.fillna(0)\n```\n\n```{python}\n# Import packages\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport geopandas as gpd\n\n# Definir Figura e Axis\nf, ax = plt.subplots(1, figsize=(9, 9))\n\n\n# Ler os dados NUTS3\ngpk = r\"data\\geo\\GPK_NUTS3.gpkg\"\n\n# Ler os dados do GeoPackage para um GeoDataFrame\ngdfnuts3 = gpd.read_file(gpk)\nprint(gdfnuts3.info())\n# Selecionar Dados Portugal Continental:\n# Fazer Seleção da NUTS1, Atributo NUTS3\n# Sem seleção a area da visualização é muito grande\ngdf_nuts3_sel = gdfnuts3[gdfnuts3['NUTS3'].str.startswith('1')]\n\nprint(gdf_nuts3_sel.info())\n\n# Fazer Merge dos dados\n# Fazer o Join, especificar: DF\ngdf_nuts3_2 = gdf_nuts3_sel.merge(df_nuts3, left_on='NUTS3', right_on='geocod', how='left')\n\n# Definir Legenda \nlgnd_kwds = {'loc': 'upper left', \n             'bbox_to_anchor': (1, 1.03), \n             'ncol': 2}\n\n# Generate the choropleth and store the axis\n# natural_breaks\nax = gdf_nuts3_2.plot(column=gdf_nuts3_2.valor, \n                      scheme='quantiles', # natural_breaks, quantiles, equal_interval \n                      k=7, \n                      cmap='YlGn', \n                      legend=True,\n                      edgecolor = 'dimgray',\n                      legend_kwds  = lgnd_kwds,\n                      ax=ax)\n \n# Remover frames, ticks e tick labels do axis\nax.set_axis_off()\n\nplt.title(json_data[0]['IndicadorDsg']) # usar a designação do indicador no titulo do mapa\nplt.show()\n```\n\n```{python}\ngdfnuts3.info()\nprint(gdf_nuts3_sel.NUTS3.unique())\nprint(df_nuts3.geocod.unique())\n# Valores unicos NUTS3 \n```\n\n### Exercício\n\n**Observações:**\n- Faz a Adaptação do código seguinte para importar outro indicador ao nível de municipio ou NUTS3\n- Ler Dados Indicador XXXX de um ano a escolha\n    - Ver pagina SMI Indicadores: https://smi.ine.pt/Indicador?clear=True\n    - Testar url antes de incluir no script\n- Importar para Pandas Dataframe as áreas NUTS3\n- Criar mapa dos resultados\n\n**Informação URL**\n- varcd: código de difusão\n- Dim1 (periódo de referência): \n    - Ano (de acordo com portal, por exemplo S7A2016<)\n    - Sem valores, devolvido dados último ano\n    - T: Dados de todos os anos\n- Dim2:\n    - Sem dados: retornados dados todas as geografias\n    - Geografias separados por vírgula\n- Dim3=T: Informação disponível no SMI\n\n```{python}\nimport requests\nimport os\nimport pandas as pd\n\n# Ler Dados Inicial para JSON\n# Indicador 0008074: Taxa de criminalida, último ano, todos os níveis geográficos, indicador \n# Categorias no SMI do Dim3: http://smi-i.ine.pt/Versao/Detalhes/902 \nproxies = {\n  'http': 'http://proxy.ine.pt:8080',\n  'https': 'http://proxy.ine.pt:8080',\n}\n\n# os.environ['http_proxy'] = 'http://proxy.ine.pt:8080'\n# os.environ['https_proxy'] = 'http://proxy.ine.pt:8080'\n\n# Dim1: Ultimo ano, Dim2: Todas as geografias \nurl = r'https://www.ine.pt/ine/json_indicador/pindica.jsp?op=2&varcd=0008265&lang=PT'\n\n# Make an HTTP GET request to fetch the JSON data from the URL\nresponse = requests.get(url)#, proxies=proxies)\n\n# Verificar Resposta\n# Respostas Possiveis\nif response.status_code == 200:\n    #Obter JSON response\n    json_data = response.json()\nelse:\n    print(\"Failed to fetch data. Status code:\", response.status_code)\n    exit()\n\nprint (type(json_data))\n\n\n# Verificar Tipo de Dados Devolvido e mostrar informação\nif isinstance(json_data, list):\n    print(\"JSON object is a list.\")\n    if json_data:\n        print(\"Numero Registos:\", len(json_data))\n        #print(\"Registo Exemplo:\", json_data[0])\n        print(\"Tipo 1º elementos:\", type(json_data[0]))\nelif isinstance(json_data, dict):\n    print(\"JSON object is a dictionary.\")\n    print(\"Keys do Object:\", list(json_data.keys()))\nelse:\n    print(\"Unknown JSON object type.\")\n\n    \n# Obter tipo de keys no dictionary\nprint(\"Keys existentes:\", list(json_data[0].keys()))\n```\n\n```{python}\n# Fazer um Loop por todos os anos\nfor ky in list(json_data[0]['Dados'].keys()):\n    print(ky)\n```\n\n```{python}\n# Obter Keys no Dados\n# Existe um Key para Cada Ano\n# Resultado json_data\nprint(\"Keys existentes nos Dados:\", list(json_data[0]['Dados'].keys()) )\n\n# Ver Tipo de conteudo 2022:\nprint(\"Tipo Objecto:\", type(json_data[0]['Dados']['2022']) )\n\n# Tipo é Listagem de Dictionary's\n# Ver conteudo e informação 1º elemento\nprint(\"Tipo primeiro elemento:\", type(json_data[0]['Dados']['2022'][0]), 'Numero Elementos:', len(json_data[0]['Dados']['2022']) )\n# Atributos de cada dictionary\n# json_data[0] = Conteudo de resposta\n# json_data[0]['Dados'] = Vamos buscar os proprios dados\n# Obter os dados do ano 2022 - deste conteudo podmeos criar DataFrame: json_data[0]['Dados']['2022']\nprint(\"Keys existentes no Ano:\", list(json_data[0]['Dados']['2022'][0].keys()) )\n```\n\n```{python}\n# criar Dataframe:\n# Para assegurar o tipo de dados deveria ser especificado o tipo de atributos das colunas \ncolumns = [\"geocod\", \"geodsg\", \"valor\"]\ndata_types = {\"geocod\": str, \"geodsg\": str, \"valor\": float}\n\n# Convert the list of dictionaries to a Pandas DataFrame\ndf_ine = pd.DataFrame(json_data[0]['Dados']['2022'], columns=columns).astype(data_types)\nprint (df_ine.head())\n```\n\n```{python}\n# Mostrar os dados ao nivel de NUTS3:\n# Filtragem no DF - Seleção Length 7\ndf_nuts3 = df_ine[df_ine['geocod'].str.len() == 7].copy()\ndf_nuts3['codmn'] = df_nuts3['geocod'].str[-4:]\nprint(df_nuts3.head())\n```\n\n```{python}\n# ImportR gEOPackage\n# Import packages\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport geopandas as gpd\n \n# Ler os dados CAOP\ngpk = r\"data\\geo\\GPK_CAOP_MN.gpkg\"\n\n# Ler os dados do GeoPackage para um GeoDataFrame\ngdfnuts3 = gpd.read_file(gpk)\nprint(gdfnuts3.head())\n```\n\n```{python}\n# Merge dos Dados:\ngdf_nuts3_2 = gdfnuts3.merge(df_nuts3, left_on='DTMN', right_on='codmn', how='left')\nprint(gdf_nuts3_2.head())\n```\n\n```{python}\n# Definir Figura e Axis\nf, ax = plt.subplots(1, figsize=(9, 9))\n\n# Mostrar Dados \n# Definir Legenda \n\nlgnd_kwds = {'loc': 'upper left', \n             'bbox_to_anchor': (1, 1.03), \n             'ncol': 2}\n\n# Generate the choropleth and store the axis\n# natural_breaks\nax = gdf_nuts3_2.plot(column=gdf_nuts3_2.valor, \n                      scheme='quantiles', # natural_breaks, quantiles, equal_interval \n                      k=7, \n                      cmap='YlGn', \n                      legend=True,\n                      edgecolor = 'dimgray',\n                      legend_kwds  = lgnd_kwds,\n                      ax=ax)\n \n# Remover frames, ticks e tick labels do axis\nax.set_axis_off()\n\nplt.title('Taxa bruta de mortalidade (‰) por Local de residência (NUTS - 2013)')\nplt.show()\n```\n\n\n## Geocoding\n\nAPI com serviços REST  \n![](images\\apis.png)\n\n**API Keys google e BING** *(vão ser eliminadas após a formação)*\n\n- GeoCode Key BING: At0TxnfnmV0hqD99JAtRPIZfPfQarPox_JCIPgRERq-cY99c1HLvqryhnkMLwIK0\n- GeoCode Key Google: AIzaSyC-tGOoI4QrYNS3AgRuzOOMb_51Gd0RTic\n\n```{python}\n#| eval: false\n# definir as variaveis proxy\n\nimport os\nos.environ['http_proxy'] = 'http://proxy.ine.pt:8080'\nos.environ['https_proxy'] = 'http://proxy.ine.pt:8080'\n```\n\nobter longitude e latitudede uma morada com o Google Maps API     \n```{python}\n# Incluir Controlo de Resposta - Invalido API Key\n\nimport requests\nimport random, time\nimport pprint\n\nproxies = {\n  'http': 'http://proxy.ine.pt:8080',\n  'https': 'http://proxy.ine.pt:8080',\n}\n\n\nAPI_KEY = \"AIzaSyC-tGOoI4QrYNS3AgRuzOOMb_51Gd0RTic\"\n\ndef geocode_address(address):\n    url = \"https://maps.googleapis.com/maps/api/geocode/json?address=\" + address + \"&key=\" + API_KEY\n    print(url)\n    response = requests.get(url)#, proxies=proxies)\n    # Mostrar Resposta JSON (para fim demonstrativos)\n    print(response)\n    # Atenção - ao utilizar chave errado - Response é differente     \n    if response.status_code == 200:\n        data = response.json()\n        pp = pprint.PrettyPrinter(indent=4)\n        pp.pprint(data)\n        latitude = data[\"results\"][0][\"geometry\"][\"location\"][\"lat\"]\n        longitude = data[\"results\"][0][\"geometry\"][\"location\"][\"lng\"]\n        return latitude, longitude\n    else:\n        return None\n\nlatitude, longitude = geocode_address(\"Rua João Morais Barbosa 12, Lisboa\")\nprint(latitude, longitude) \n\n# Para Assegurar de não ultrapassar o limite de 2 pedidos por segundo seria necessário acresentar codigo deste tipo:\ntime.sleep(random.uniform(0, 3)+0.1)\n```\n\n### Geopandas\n\n```{python}\nimport geopandas as gpd\n```\n\ngeocode de uma morada  \n```{python}\n# GeoReference Morada simples:\nimport matplotlib.pyplot as plt\nfrom shapely.geometry import Point\nimport geopandas as gpd\nimport pandas as pd\nimport folium\n# import os\n# os.environ['http_proxy'] = 'http://proxy.ine.pt:8080'\n# os.environ['https_proxy'] = 'http://proxy.ine.pt:8080'\n\n\n# Chamar Função GeoCode\n# Rua  Prof Luciano Mota vieira 42, Ponta Delgada\nres_geo = gpd.tools.geocode(\"Rua Prof Luciano Mota vieira 42, Ponta Delgada\",\n                            provider = \"nominatim\", \n                            user_agent=\"Intro Geocode\")\n\nprint(res_geo)\n\n# # Atenção esta linha dá um erro caso não foi obtido nenhum resultado\n# # Sera necessário fazer a validação de existencia de Geometria (utiliza Shapely)\n# if (not res_geo['geometry'][0].is_empty):\n#     print ('Visualizar')\n#     res_geo.explore(marker_type = 'marker',edgecolor = 'black')\n# else:\n#     print('Nao foi obtido nenhum resultado')\n# \n# print(len(res_geo))\n# res_geo.explore(marker_type = 'marker',edgecolor = 'black')\n\n```\n\ngeocode de um ficheiro com moradas  \n```{python}\n# GeoReference Morada simples:\nimport geopandas as gpd\nimport pandas as pd\nimport os\nfrom shapely.geometry import Point\n\n# os.environ['http_proxy'] = 'http://proxy.ine.pt:8080'\n# os.environ['https_proxy'] = 'http://proxy.ine.pt:8080'\n\n# Ler Ficheiros ocm Moradas\ninputfile = r\"data\\geo\\Ensino_Nao_Superior_Amadora.xlsx\"\npd_escolas = pd.read_excel(inputfile)\n\n# Criar nova coluna morada\npd_escolas['morada2'] = pd_escolas['MORADA'].astype(str) + ' ' + pd_escolas['CTT_COD'].astype(str) + ' ' + pd_escolas['CTT_AUX'].astype(str) + ' ' + pd_escolas['LOCALIDADE'].astype(str)\n\n\n# Fazer Seleção de apenas alguns registos:\npd_escolas = pd_escolas.head(10)\n\n# Chamar Função GeoCode\ntry:\n    res_geo = gpd.tools.geocode(pd_escolas.morada2)\nexcept Exception as e:\n    print(f\"Aconteceu um erro a utilizar o geocode() de geopandas: {e}\")    \n    \n    \n#print(res_geo.info())\n#print(pd_escolas.head())\n\nprint (f\"Nº de Registos do ficheiro: {len(pd_escolas)}\")\n```\n\nselecionar os registos com geometria  \n```{python}\nfrom shapely.geometry import Point\nimport geopandas as gpd\n\n# Mostrar Resultado:\n# Selecionar Pontos com Geometria:\n# Crie uma máscara booleana para identificar geometrias válidas (resultado Pandas Series)\n# ~: Siginifca not (será seleccionado o inverso) - \nmask_valid_geometry = ~res_geo['geometry'].apply(lambda x: x.is_empty)\n\n# Selecione os registros com geometria válida\nres_geo_valid = res_geo[mask_valid_geometry]\n\n\nprint (f\"Nº de Registos do ficheiro: {len(pd_escolas)}\",\"\\n\",\n      f\"Nº de Registos resultado: {len(res_geo_valid)}\")\n\n\n# Mostrar a geografia obtida\nres_geo_valid.explore(marker_type = 'marker',edgecolor = 'black')\n```\n\n\n### Geopy\n\ngeocode com nomination  \n```{python}\nfrom geopy.geocoders import Nominatim\n\n# Morada para geocode\naddress = \"Rua do comercio 42, vilar formoso\"\n\n# Inicialização do geocodificador com o serviço Nominatim\ngeolocator = Nominatim(user_agent=\"my_geocoder\")\n\n# Geocode da morada\n# Opções para mostrar: addressdetails =True, limit = 4, extratags  = Tru\n# \nlocation = geolocator.geocode(address)\nprint(location)\n\n# Verificando o tipo de resultado JSON retornado\nif location:\n    print(f\"Latitude: {location.latitude}, Longitude: {location.longitude}\")\n    print(f\"Tipo de objeto JSON retornado: {type(location.raw)}\")\n    print(\"Exemplo de parte do JSON retornado:\")\n    print(location.raw)\nelse:\n    print(\"Morada não encontrada ou geocodificação não foi possível.\")\n    \n```\n\ngeocode com google  \n```{python}\nfrom geopy.geocoders import GoogleV3\n\n# Sua chave de API do Google Maps\napi_key = 'AIzaSyC-tGOoI4QrYNS3AgRuzOOMb_51Gd0RTic'\n\n# Endereço para geocode\naddress = \"Av Antonio José Almeida, Lisboa\"\n\n# Inicialização do geocodificador com o serviço Google Maps usando a chave de API\ngeolocator = GoogleV3(api_key=api_key)\n\n\n# Geocode da morada\nlocation = geolocator.geocode(address)\nprint (location)\n\n# Verificando os resultados\nif location:\n    print(f\"Latitude: {location.latitude}, Longitude: {location.longitude}\")\n    print(location.raw)\nelse:\n    print(\"Morada não encontrada ou geocodificação não foi possível.\")\n```\n\ngeocode com bing  \n```{python}\nfrom geopy.geocoders import Bing\n\n# Sua chave de API do Bing Maps\nbing_api_key = 'At0TxnfnmV0hqD99JAtRPIZfPfQarPox_JCIPgRERq-cY99c1HLvqryhnkMLwIK0'\n\n# Endereço para geocode\naddress = \"Rua da urbanização do tanque 8, Funchal\"\n\n# Inicialização do geocodificador com o serviço Bing Maps usando a chave de API\ngeolocator = Bing(api_key=bing_api_key)\n\n# Geocode da morada\nlocation = geolocator.geocode(address)\n\nprint(location.raw,'\\n')\n\n# Verificando os resultados\nif location:\n    print(f\"Latitude: {location.latitude}, Longitude: {location.longitude}\")\nelse:\n    print(\"Morada não encontrada ou geocodificação não foi possível.\")\n\n```\n\nimportar um ficheiro inteiro (com bing)  \n```{python}\nimport pandas as pd\nfrom geopy.geocoders import Bing\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Seus dados\ninputfile = r\"data\\geo\\Ensino_Nao_Superior_Amadora.xlsx\"\nbing_api_key = 'At0TxnfnmV0hqD99JAtRPIZfPfQarPox_JCIPgRERq-cY99c1HLvqryhnkMLwIK0'\n\n# Colunas CTT_COD e CTT_AUX são importados como numero\ncolumns_para_string = ['CTT_COD', 'CTT_AUX']\n\n# Leitura do arquivo Excel especificando os tipos de dados das colunas\ndf = pd.read_excel(inputfile, dtype={col: str for col in columns_para_string})\n\n# Concatenando os atributos desejados para formar o endereço\ndf['endereco'] = df['MORADA'] + ', ' + df['CTT_COD'] + ' ' + df['CTT_AUX'] + ', ' + df['LOCALIDADE']\n\n# Importar apenas alguns registos\ndf = df.head(20)\n\n# Inicializando o geocodificador com o serviço Bing\ngeolocator = Bing(api_key=bing_api_key)\n\n# Função para obter a localização e a qualidade da resposta\ndef get_location_info(address):\n    try:\n        location = geolocator.geocode(address)\n        return location, location.raw['confidence']\n    except:\n        return None, None\n\n# Aplicando a função para obter a localização e a qualidade da resposta\ndf['location_info'] = df['endereco'].apply(get_location_info)\n\n\n# Extraindo as coordenadas e a qualidade da resposta para colunas separadas\n# Atenção a ordem longitude (x) e latitude (y)!\ndf['coordinates'] = df['location_info'].apply(lambda loc: (loc[0].longitude, loc[0].latitude) if loc[0] else None)\ndf['quality'] = df['location_info'].apply(lambda loc: loc[1] if loc[1] else None)\n\n# Criando o GeoDataFrame com base nas coordenadas obtidas\ngeometry = [Point(xy) if xy else None for xy in df['coordinates']]\n# Criar gdf de resultado - com indicação do CRS\ngdfBing = gpd.GeoDataFrame(df, geometry=geometry, crs=\"EPSG:4326\")\n\n\n\n# Corrigir para registos onde não existe GeoMetry\n# Neste caso a coluna geometry is Null\nmask_valid_geometry = gdfBing['geometry'].notnull()\n\n# Selecione os registros com geometria válida\ngdfBing = gdfBing[mask_valid_geometry]\n\nprint (f\"Nº de Registos do ficheiro: {len(df)}\",\"\\n\",\n      f\"Nº de Registos resultado: {len(gdfBing)}\")\n\n\n# Mostrar GeoDataFrame resultante\nprint(gdfBing.head())\n\nprint()\ngdfBing.info()\n```\n\n```{python}\n# Exportar o resultado obtido (coluna location_info):\ndf['location_info'].to_csv(r'data\\geo\\outdfbing.txt', sep='\\t')\n```\n\nvisualizar com `explore`  \n```{python}\ngdfBing = gdfBing.drop(columns=['location_info'])\ngdfBing.explore(marker_type = 'marker',edgecolor = 'black')\n```\n\n### Dados OSMX com OSMnx\n\nOpenStreetMap (OSM)\n\npesquisa de dados por lugar  \n```{python}\nimport osmnx as ox\nimport geopandas as gpd\n#import matplotlib.pyplot as plt\n\n# Definir o lugar para qual queremos dados\nplace = \"Porto, PT\"\n\n# Verificar Existencia Place\ntry:\n    result = ox.geocoder.geocode(place)\n    print(f\"The geocoded result for {place} is: {result}\")\nexcept Exception as e:\n    print(f\"O place não existe: {place}\")\n    \ntags = {\"highway\": \"bus_stop\"}\n\ntry:\n    gdf_bus = ox.features_from_place(place, tags)\nexcept Exception as e:\n    print(f\"Não existem elementos para este tag: {tags}\")    \n\n    \nprint(gdf_bus[[\"bench\",'name','network','operator','route_ref','departures_board', 'brand' ]].head(8))\n\ngdf_bus.explore(#column = 'cuisine',\n              legend = True,\n            marker_type = 'marker',\n                  edgecolor = 'black')\n```\n\n\nPesquisa de dados por extensão de uma GDF  \n\neste exemplo faz a importação dos restaurantes existentes no OSM  \n```{python}\nimport osmnx as ox\nimport geopandas as gpd\n#import matplotlib.pyplot as plt\nfrom shapely.geometry import box\n\n# Por exemplo Obter Dados o Extento do GPK que utilizamos os notebooks\n# Processo importar \ngpk = r'data\\geo\\BGRI2021_1106.gpkg'\ngdf1106 = gpd.read_file(gpk,encoding='utf-8')\n\n# Obter a extensão do GeoDataFrame\nxmin, ymin, xmax, ymax = gdf1106.total_bounds\n\n# Criar um poligono que representa a extensão\nextent_polygon = box(xmin, ymin, xmax, ymax)\n\n# Atenção O CRS dos dados do OSM é EPSG 4326 - Necesistamos de transformar o poligono para 4326\n\n# Isto pode ser efetuado em GeoPandas (alternativa package pyproj)\n# Necessário de definir o CRS par apoder fazer a projeção dos dados\nextent_gdf = gpd.GeoDataFrame(geometry=[extent_polygon], crs = gdf1106.crs) \n\n# Mudar a projeção para CRS dos dados OSM - 4326:\nextent_gdf2 = extent_gdf.to_crs('EPSG:4326')\n\n# Esta GDF consiste de 1 registo com o poligono\n\n# Definir Tags   \ntags = {\"amenity\": \"restaurant\"}\n\n# Necessário try e except para validar o input \ntry:\n    gdf_restaurants = ox.features_from_polygon(extent_gdf2['geometry'][0], tags)\nexcept Exception as e:\n    print(f\"Não existem elementos para este tag: {tags}\")\n    \n\n# Vai dar erro se houver problema com tags ou dados existentes    \ngdf_restaurants.explore(column = 'cuisine',\n        legend = True,\n        marker_type = 'marker',\n        edgecolor = 'black')\n```\n\n### Exportar dados\n\n```{python}\n#| eval: false\ngdf_restaurants.to_file(r'data\\geo\\osm_restaurants1106.gpkg', layer='RESTAURANTS1106', driver=\"GPKG\")\n```\n\n### Exercício\n- Tentar importar mais moradas e melhorar a qualidade do endereço de input\n- Importar o Ficheiro \"Ensino_Nao_Superior_Amadora.xlsx\" utilizando Google ou Nomantim:\n    - Ver o codigo de importar utilizando Bing, com a seguinte diferença\n    ~~~Python\n    # Inicializar o o geocodificador com o serviço Google\n    geolocator = GoogleV3(api_key=google_api_key)\n\n    # Funcao get_location_info para geocodificar endereco\n    def get_location_info(address):\n        try:\n            location = geolocator.geocode(address)\n            return location, location.raw['types']\n        except:\n            return None, None\n    ~~~\n    - Ver o codigo de importar utilizando Bing, com a seguinte diferença\n    ~~~Python\n    # Inicializar o o geocodificador com o serviço Nominatim\n    geolocator = Nominatim(user_agent=\"my_geocoder\")\n\n    # Funcao get_location_info para geocodificar endereco\n    def get_location_info(address):\n        try:\n            location = geolocator.geocode(address)\n            return location, location.raw['osm_type']  # Adjust according to the response structure\n        except:\n            return None, None\n\n    ~~~\n    - Ajuda Geocoders GeoPY: https://geopy.readthedocs.io/en/latest/#geocoders\n- Importar as escolas de Amadora utilizando o OSMnx (tag amenity e school)\n    - Ver o exemplo neste notebook\n- Visualizar os diferentes Resultados obtidos:\n    - É possivel de utilizar o MatplotLib para visualizar, codigo exemplo (será necessário adicionar as outras gdf\n    ~~~Python\n    import contextily as ctx\n    from shapely.geometry import Point\n\n    # Criar variáveis para a figura\n    f, ax = plt.subplots(1, figsize=(9, 9))\n\n    # Visualizar a GDF\n    gdfBing.plot(legend = False,\n                   ax = ax,\n                  color= 'green' )\n\n    # Add basemap do contextily\n    ctx.add_basemap(\n        ax,\n        crs=gdfGoogle.crs,\n        source=ctx.providers.CartoDB.VoyagerNoLabels,\n    )\n    ~~~\n\n\n**Atenção:** Cuidado com a quantidade de endereços a georrefenciar\n\n\n#### Georeferenciar dados com Google\n\n```{python}\nimport pandas as pd\nfrom geopy.geocoders import GoogleV3\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Importar os Dados\ninputfile = r\"data\\geo\\Ensino_Nao_Superior_Amadora.xlsx\"\ngoogle_api_key = 'AIzaSyC-tGOoI4QrYNS3AgRuzOOMb_51Gd0RTic'\n\n# Colunas CTT_COD e CTT_AUX são importados como números\ncolumns_para_string = ['CTT_COD', 'CTT_AUX']\n\n# Ler EXCEl e indicar que colunas CTT_COD e CTT_AUX são texto\ndf = pd.read_excel(inputfile, dtype={col: str for col in columns_para_string})\n\n# Criar nova coluna com endereco\ndf['endereco'] = df['MORADA'] + ', ' + df['CTT_COD'] + ' ' + df['CTT_AUX'] + ', ' + df['LOCALIDADE']\n\n# Importar apenas alguns registos\ndf = df.head(20)\n\n# Inicializar o o geocodificador com o serviço Google\ngeolocator = GoogleV3(api_key=google_api_key)\n\n# Funcao get_location_info para geocodificar endereco\ndef get_location_info(address):\n    try:\n        location = geolocator.geocode(address)\n        return location, location.raw['types']\n    except:\n        return None, None\n\n# Aplicando a função para obter a localização e a qualidade da resposta\ndf['location_info'] = df['endereco'].apply(get_location_info)\n\n# Extraindo as coordenadas e a qualidade da resposta para colunas separadas\n# Atenção a ordem longitude (x) e latitude (y)!\ndf['coordinates'] = df['location_info'].apply(lambda loc: (loc[0].longitude, loc[0].latitude) if loc[0] else None)\ndf['quality'] = df['location_info'].apply(lambda loc: loc[1] if loc[1] else None)\n\n# Criar o GeoDataFrame com base nas coordenadas obtidas\ngeometry = [Point(xy) if xy else None for xy in df['coordinates']]\n# Criar gdf de resultado - com indicação do CRS\ngdfGoogle = gpd.GeoDataFrame(df, geometry=geometry, crs=\"EPSG:4326\")\n\n# Corrigir para registos onde não existe GeoMetry\n# Neste caso a coluna geometry is Null\nmask_valid_geometry = gdfGoogle['geometry'].notnull()\n\n# Selecione os registros com geometria válida\ngdfGoogle = gdfGoogle[mask_valid_geometry]\n\nprint (f\"Nº de Registos do ficheiro: {len(df)}\",\"\\n\",\n      f\"Nº de Registos resultado: {len(gdfGoogle)}\")\n\n# Mostrar parte do Resultado\nprint(gdfGoogle.head())\n```\n\n\n```{python}\n# Apagar atributo location_info \ngdfGoogle = gdfGoogle.drop(columns=['location_info'])\ngdfGoogle.explore(marker_type = 'marker',edgecolor = 'black')\n```\n\n#### Importar dados Nominatim\n\n```{python}\nimport pandas as pd\nfrom geopy.geocoders import Nominatim\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Importar os Dados\ninputfile = r\"data\\geo\\Ensino_Nao_Superior_Amadora.xlsx\"\n\n# Colunas CTT_COD e CTT_AUX são importados como números\ncolumns_para_string = ['CTT_COD', 'CTT_AUX']\n\n# Ler EXCEl e indicar que colunas CTT_COD e CTT_AUX são texto\ndf = pd.read_excel(inputfile, dtype={col: str for col in columns_para_string})\n\n# Criar nova coluna com endereco\ndf['endereco'] = df['MORADA'] + ', ' + df['CTT_COD'] + ' ' + df['CTT_AUX'] + ', ' + df['LOCALIDADE']\n\n# Importar apenas alguns registos\ndf = df.head(20)\n\n# Inicializar o o geocodificador com o serviço Nominatim\ngeolocator = Nominatim(user_agent=\"my_geocoder\")\n\n# Funcao get_location_info para geocodificar endereco\ndef get_location_info(address):\n    try:\n        location = geolocator.geocode(address)\n        return location, location.raw['osm_type']  # Adjust according to the response structure\n    except:\n        return None, None\n\n# Aplicando a função para obter a localização e a qualidade da resposta\ndf['location_info'] = df['endereco'].apply(get_location_info)\n\n# Extraindo as coordenadas e a qualidade da resposta para colunas separadas\n# Atenção a ordem longitude (x) e latitude (y)!\ndf['coordinates'] = df['location_info'].apply(lambda loc: (loc[0].longitude, loc[0].latitude) if loc[0] else None)\ndf['quality'] = df['location_info'].apply(lambda loc: loc[1] if loc[1] else None)\n\n# Criar o GeoDataFrame com base nas coordenadas obtidas\ngeometry = [Point(xy) if xy else None for xy in df['coordinates']]\n# Criar gdf de resultado - com indicação do CRS\ngdfNominatim = gpd.GeoDataFrame(df, geometry=geometry, crs=\"EPSG:4326\")\n\n# Corrigir para registos onde não existe GeoMetry\n# Neste caso a coluna geometry is Null\nmask_valid_geometry = gdfNominatim['geometry'].notnull()\n\n# Selecione os registros com geometria válida\ngdfNominatim = gdfNominatim[mask_valid_geometry]\n\nprint (f\"Nº de Registos do ficheiro: {len(df)}\",\"\\n\",\n      f\"Nº de Registos resultado: {len(gdfNominatim)}\")\n\n\n# Mostrar GDf Resultado\nprint(gdfNominatim.head())\n```\n\n\n```{python}\n# Google não tem problema com o atributo location_info\ngdfNominatim = gdfNominatim.drop(columns=['location_info'])\ngdfNominatim.explore(marker_type = 'marker',edgecolor = 'black')\n```\n\n#### Importar dados OSM\n\n```{python}\nimport osmnx as ox\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\n# Definir o lugar para qual queremos dados\nplace = \"Amadora, PT\"\n\n# Verificar Existencia Place\ntry:\n    result = ox.geocoder.geocode(place)\n    print(f\"The geocoded result for {place} is: {result}\")\nexcept Exception as e:\n    print(f\"O place não existe: {place}\")\n    \ntags = {\"amenity\": \"school\"}\n\ntry:\n    gdf_school = ox.features_from_place(place, tags)\nexcept Exception as e:\n    print(f\"Não existem elementos para este tag: {tags}\")    \n\n    \ngdf_school.explore(marker_type = 'marker',\n                  edgecolor = 'black')\n```\n\nmostrar todos os resultados  \n```{python}\nimport contextily as ctx\nfrom shapely.geometry import Point\n\n# Criar variáveis para a figura\nf, ax = plt.subplots(1, figsize=(9, 9))\n\n\n# Visualizar a GDF\ngdfBing.plot(legend = False,\n               ax = ax,\n              color= 'green' )\n\n# Add basemap do contextily\nctx.add_basemap(\n    ax,\n    crs=gdfGoogle.crs,\n    source=ctx.providers.CartoDB.VoyagerNoLabels,\n)\n\n\n\n# Visualizar a GDF\ngdfNominatim.plot(legend = False,\n               ax = ax,\n              color= 'purple' )\n\n# Visualizar a GDF\ngdfGoogle.plot(legend = False,\n               ax = ax,\n              color= 'red' )\n\n\n# Visualizar a GDF\ngdf_school.plot(legend = False,\n               ax = ax,\n              color= 'blue' )\n\n# Add basemap do contextily\nctx.add_basemap(\n    ax,\n    crs=gdfGoogle.crs,\n    source=ctx.providers.CartoDB.VoyagerNoLabels,\n)\n\n\nax.set_axis_off()\n```\n\n\n<br>\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["epub.css"],"output-file":"900-mod9.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","bibliography":["references.bib"],"theme":{"light":"flatly","dark":"solar"}},"extensions":{"book":{"multiFile":true}}},"epub":{"identifier":{"display-name":"ePub","target-format":"epub","base-format":"epub"},"execute":{"fig-width":5,"fig-height":4,"fig-format":"png","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"epub","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":false,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"default-image-extension":"png","html-math-method":"mathml","to":"epub","toc":true,"css":["epub.css"],"output-file":"900-mod9.epub"},"language":{"toc-title-document":"Índice","toc-title-website":"Nesta página","related-formats-title":"Outros formatos","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Fonte","section-title-abstract":"Resumo","section-title-appendices":"Apêndices","section-title-footnotes":"Notas de rodapé","section-title-references":"Referências","section-title-reuse":"Reuso","section-title-copyright":"Direito autoral","section-title-citation":"Citação","appendix-attribution-cite-as":"Por favor, cite este trabalho como:","appendix-attribution-bibtex":"BibTeX","title-block-author-single":"Autor","title-block-author-plural":"Autores","title-block-affiliation-single":"Afiliação","title-block-affiliation-plural":"Afiliações","title-block-published":"Data de Publicação","title-block-modified":"Data de Modificação","callout-tip-title":"Dica","callout-note-title":"Nota","callout-warning-title":"Aviso","callout-important-title":"Importante","callout-caution-title":"Cuidado","code-summary":"Código","code-tools-menu-caption":"Código","code-tools-show-all-code":"Mostrar o código","code-tools-hide-all-code":"Esconder o código","code-tools-view-source":"Ver o código fonte","code-tools-source-code":"Código fonte","code-line":"Linha","code-lines":"Linhas","copy-button-tooltip":"Copiar para a área de transferência","copy-button-tooltip-success":"Copiada","repo-action-links-edit":"Editar essa página","repo-action-links-source":"Ver o código fonte","repo-action-links-issue":"Criar uma issue","back-to-top":"De volta ao topo","search-no-results-text":"Nenhum resultado","search-matching-documents-text":"documentos correspondentes","search-copy-link-title":"Copiar link para a busca","search-hide-matches-text":"Esconder correspondências adicionais","search-more-match-text":"mais correspondência neste documento","search-more-matches-text":"mais correspondências neste documento","search-clear-button-title":"Limpar","search-detached-cancel-button-title":"Cancelar","search-submit-button-title":"Enviar","search-label":"Procurar","toggle-section":"Alternar seção","toggle-sidebar":"Alternar barra lateral","toggle-dark-mode":"Alternar modo escuro","toggle-reader-mode":"Alternar modo de leitor","toggle-navigation":"Alternar de navegação","crossref-fig-title":"Figura","crossref-tbl-title":"Tabela","crossref-lst-title":"Listagem","crossref-thm-title":"Teorema","crossref-lem-title":"Lema","crossref-cor-title":"Corolário","crossref-prp-title":"Proposição","crossref-cnj-title":"Conjetura","crossref-def-title":"Definição","crossref-exm-title":"Exemplo","crossref-exr-title":"Exercício","crossref-ch-prefix":"Capítulo","crossref-apx-prefix":"Apêndice","crossref-sec-prefix":"Seção","crossref-eq-prefix":"Equação","crossref-lof-title":"Lista de Figuras","crossref-lot-title":"Lista de Tabelas","crossref-lol-title":"Lista de Listagens","environment-proof-title":"Comprovação","environment-remark-title":"Comentário","environment-solution-title":"Solução","listing-page-order-by":"Ordenar por","listing-page-order-by-default":"Pré-selecionado","listing-page-order-by-date-asc":"Mais velho","listing-page-order-by-date-desc":"O mais novo","listing-page-order-by-number-desc":"Decrescente","listing-page-order-by-number-asc":"Crescente","listing-page-field-date":"Data","listing-page-field-title":"Título","listing-page-field-description":"Descrição","listing-page-field-author":"Autor","listing-page-field-filename":"Nome do arquivo","listing-page-field-filemodified":"Arquivo modificado","listing-page-field-subtitle":"Subtítulo","listing-page-field-readingtime":"Tempo de leitura","listing-page-field-categories":"Categorias","listing-page-minutes-compact":"{0} minutos","listing-page-category-all":"Tudo","listing-page-no-matches":"Nenhum item correspondente"},"metadata":{"bibliography":["references.bib"],"lang":"pt","date":"2024-03-31"},"extensions":{"book":{"selfContainedOutput":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":true,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":"H","fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","include-in-header":{"text":"\\usepackage{fvextra}\n\\DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\\\\{\\}}\n\\areaset[0.50in]{4.5in}{8in}\n"},"include-before-body":{"text":"\\RecustomVerbatimEnvironment{verbatim}{Verbatim}{\n   showspaces = false,\n   showtabs = false,\n   breaksymbolleft={},\n   breaklines\n   % Note: setting commandchars=\\\\\\{\\} here will cause an error \n}  \n"},"output-file":"900-mod9.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"block-headings":true,"bibliography":["references.bib"],"documentclass":"scrbook","classoption":["paper=6in:9in","pagesize=pdftex","headinclude=on","footinclude=on","12pt"]},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","epub","pdf"]}